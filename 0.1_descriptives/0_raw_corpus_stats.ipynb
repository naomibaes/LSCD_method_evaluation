{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Naomi Baes and Chat GPT\n",
    "\n",
    "**Purpose**: This script gets corpus statistics for the raw-est version of the corpus (used for preprocessing in \"0.0_corpus_preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get corpus stats: Raw corpus (1970-2016)\n",
    "\n",
    "Note: The raw psychology corpus has a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the first 5 lines of the corpus:\n",
      "abstract ||||| publication_year ||||| journal_title_old ||||| journal_title\n",
      "The withdrawal response of the land snail helix albolabris disappears on appropriate repetition of the (mechanical) stimulus. In the usual terminology, the snail becomes habituated to the stimulus. The disappearance of the response cannot be due to fatigue, as this term is usually understood; for (a) a single stimulus may be sufficient to effect it, (b) more intense stimulation will, under conditions not quantitatively ascertained, remove the habituation, a fact difficult to reconcile with the ordinary conception of fatigue, (c) cases were observed where the habituation took longer to re-effect after the extraneous stimulus than before. Habituation disappears after appropriate rest. It may be deepened by further stimulation after response has ceased. The hypothesis is put forward of a physiological state or process tending to diminish action; such process would be intensified by appropriate repetition of the existing stimulus, and diminished by appropriate rest and extraneous stimulation. A similar hypothesis is made to explain the extinction of conditioned responses by Pavlov, who calls the underlying process Inhibition. The phenomenon investigated, and extinction of conditioned reflexes probably have the same explanation. With reference to the phenomena of habituation, the snail, as a biological system, behaves in the manner that would be expected of a system obeying Le Chatelier's rule. ||||| 1930 ||||| Psychologische Forschung ||||| Psychological Research\n",
      "In this section it is concluded that velocity is perceived directly and is dynamically conditioned by the structure and general properties of the visual field in which the movement occurs. The visual perception of velocity follows dynamic laws that are not immediately deducible from the velocity of the stimulus as physically defined. No physiological theory is offered but it is pointed out that the theory of physiological Gestalten is essentially correct in its basic assumptions concerning the perception of movement. The investigation has bearing on the problems of movement thresholds, movement after-images and the perception of time. ||||| 1931 ||||| Psychologische Forschung ||||| Psychological Research\n",
      "The equation, phenomenal velocity=phenomenal space/phenomenal time-, v=st, was proven in the following manner. Five cases where variation in the structure of the movement field causes variation in the phenomenal velocity were tested to find out if to the variation in phenomenal velocity corresponding variation in phenomenal time (or phenomenal space) of the movement were to be found. The results of these tests were in close agreement, with the values predicted, from the facts known about phenomenal velocity, on the supposition that the equation held. From this it is concluded that all those structural variations that increase the phenomenal velocity of a movement either increase the phenomenal space or shorten the phenomenal time for equal space correspondingly 2. In far the greater number of cases, the variation is caused in the phenomenal time, and hence it is concluded that impression of duration gained by watching objects in visual movement fields is conditioned by the properties of the field in which the movement occurs. These variations in the flow of phenomenal time are not isolated cases which could be explained as illusions, but are continuous variations conditioned by practically any change in the structure of the movement field. Time where there is movement (filled time) is on the whole phenomenally longer than time marked off by disparate stimuli (unfilled time). This ratio varies, however, in accordance with the structure of the field in which the movement (filled time) occurs. ||||| 1931 ||||| Psychologische Forschung ||||| Psychological Research\n",
      "A wide range of individual differences in the ability to identify facial expressions of emotion has been reported. As evidence that these inequalities are due in large part to differences of practice in reacting to expressive criteria, rather than to innate factors, F. H. Allport has offered the data from an experimental observation of the effects of training subjects of varying ability for fifteen minutes in the analysis of facial expressions. The gain in score made by his subjects on the facial expression test after the training period was roughly inversely proportional to their original standing; i.e., the less proficient persons gained the most and the more proficient gained the least. Repeating this procedure with larger groups of subjects, both with the same and longer study periods, the writer largely confirmed Allport's data. However, a control experiment, affording no opportunity for study, yielded similar data, except that on the average no gain in score resulted. The inverse relationship between original ability and amount of gain or loss should not, therefore, be attributed to the effects of training. Further analysis shows that when the reliability of the facial expression test, found by retesting a group of subjects, is taken into account, the negative coefficient practically disappears. The negative coefficient, upon which Allport bases his theory, is thus found to result in this study from the erroneous assumption that the reliability of the facial expression test is perfect. The writer, though inclined to agree with Allport's theory, concludes that this type of experimental evidence, when closely scrutinized, fails to support the theory. ||||| 1932 ||||| The Journal of General Psychology ||||| Journal of General Psychology\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_files = [\n",
    "    \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/Psychology/abstract_year_journal.csv.mental\"\n",
    "]\n",
    "\n",
    "def preview_corpus(file_path, num_lines=5):\n",
    "    \"\"\"\n",
    "    Prints the first few lines of the corpus file.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the corpus file.\n",
    "        num_lines: Number of lines to print (default is 5).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Showing the first {num_lines} lines of the corpus:\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i >= num_lines:\n",
    "                break\n",
    "            print(line.strip())  # Strip any leading/trailing whitespace\n",
    "\n",
    "# Add this call to your main() function or run it separately\n",
    "if __name__ == \"__main__\":\n",
    "    # Preview the first 5 lines of the corpus\n",
    "    for file_path in input_files:\n",
    "        preview_corpus(file_path, num_lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: abstract_year_journal.csv.mental\n",
      "  Tokens: 142093681\n",
      "  Lines: 859704\n",
      "  Min Year: 1970\n",
      "  Max Year: 2019\n",
      "\n",
      "Corpus statistics written to output\\corpus_stats.txt\n"
     ]
    }
   ],
   "source": [
    "def filter_corpus(input_file, output_file, year_range=(1970, 2019)):\n",
    "    \"\"\"\n",
    "    Filters lines from the input file based on the year range and writes the filtered lines to the output file.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input corpus file.\n",
    "        output_file: Path to write the filtered output.\n",
    "        year_range: Tuple of integers representing the minimum and maximum year (inclusive).\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', encoding='utf-8') as fout:\n",
    "        for line in fin:\n",
    "            parts = line.strip().split(' ||||| ')\n",
    "            if len(parts) >= 2:\n",
    "                year_str = parts[1].strip()\n",
    "                if year_str.isdigit():\n",
    "                    year = int(year_str)\n",
    "                    if year_range[0] <= year <= year_range[1]:\n",
    "                        fout.write(line)\n",
    "\n",
    "\n",
    "def process_corpus(file_path, year_range=(1970, 2019), skip_header=False):\n",
    "    \"\"\"\n",
    "    Processes a corpus file, filters lines based on year range, and calculates statistics.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the corpus file.\n",
    "        year_range: Tuple of integers representing the minimum and maximum year (inclusive).\n",
    "        skip_header: Whether to skip the header line in the input file (default is False).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing corpus statistics or None if file not found.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Filter lines based on year range\n",
    "    filtered_corpus_path = f\"{file_path}.filtered\"\n",
    "    filter_corpus(file_path, filtered_corpus_path, year_range)\n",
    "\n",
    "    # Calculate statistics\n",
    "    stats = {\"tokens\": 0, \"lines\": 0, \"min_year\": float('inf'), \"max_year\": float('-inf')}\n",
    "    with open(filtered_corpus_path, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            stats[\"tokens\"] += len(line.split())\n",
    "            stats[\"lines\"] += 1\n",
    "            parts = line.strip().split(' ||||| ')\n",
    "            if len(parts) >= 2:\n",
    "                year = int(parts[1])\n",
    "                stats[\"min_year\"] = min(stats[\"min_year\"], year)\n",
    "                stats[\"max_year\"] = max(stats[\"max_year\"], year)\n",
    "\n",
    "    # Remove the filtered corpus file\n",
    "    os.remove(filtered_corpus_path)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Define year range\n",
    "    year_range = (1970, 2019)\n",
    "\n",
    "    # Process each corpus and store results\n",
    "    corpus_stats = []\n",
    "    for file_path in input_files:\n",
    "        stats = process_corpus(file_path, year_range)  # Removed skip_header argument\n",
    "        if stats:\n",
    "            # Extract specific values\n",
    "            tokens = stats[\"tokens\"]\n",
    "            lines = stats[\"lines\"]\n",
    "            min_year = stats[\"min_year\"]\n",
    "            max_year = stats[\"max_year\"]\n",
    "            corpus_name = os.path.basename(file_path)  # Get the name of the corpus\n",
    "\n",
    "            # Print corpus statistics\n",
    "            print(f\"Corpus: {corpus_name}\")\n",
    "            print(f\"  Tokens: {tokens}\")\n",
    "            print(f\"  Lines: {lines}\")\n",
    "            print(f\"  Min Year: {min_year}\")\n",
    "            print(f\"  Max Year: {max_year}\\n\")\n",
    "\n",
    "            # Append the stats to corpus_stats\n",
    "            corpus_stats.append(stats)\n",
    "\n",
    "    # Print or save corpus statistics (modify as needed)\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(\"output\", exist_ok=True)  # Create the \"output\" folder if it doesn't exist\n",
    "\n",
    "    with open(os.path.join(\"output\", \"corpus_stats.txt\"), \"w\") as f:  # Use 'w' mode to overwrite the file\n",
    "        for corpus_stat in corpus_stats:\n",
    "            # Extract specific values (modify as needed)\n",
    "            tokens = corpus_stat[\"tokens\"]\n",
    "            lines = corpus_stat[\"lines\"]\n",
    "            min_year = corpus_stat[\"min_year\"]\n",
    "            max_year = corpus_stat[\"max_year\"]\n",
    "\n",
    "            # Write extracted values to the file\n",
    "            f.write(f\"Corpus statistics:  {corpus_name}\\n  Tokens: {tokens}\\n  Lines: {lines}\\n  Min Year: {min_year}\\n  Max Year: {max_year}\\n\\n\")\n",
    "\n",
    "    print(f\"Corpus statistics written to {os.path.join('output', 'corpus_stats.txt')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range: Min year - Max year\n",
    "\n",
    "Note: The psychology corpus has a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: abstract_year_journal.csv.mental\n",
      "  Tokens: 133017962\n",
      "  Lines: 871337\n",
      "  Min Year: 1930\n",
      "  Max Year: 2019\n",
      "\n",
      "Corpus statistics written to output\\corpus_stats.all.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_corpus(file_path, skip_header=False):\n",
    "    \"\"\"\n",
    "    Processes a corpus file, filters lines based on year range, and calculates statistics.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the corpus file.\n",
    "        skip_header: Whether to skip the header line in the input file (default is False).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing corpus statistics or None if file not found.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize statistics\n",
    "    stats = {\"tokens\": 0, \"lines\": 0, \"min_year\": float('inf'), \"max_year\": float('-inf')}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as fin:\n",
    "        if skip_header:\n",
    "            next(fin)  # Skip the header line (if applicable)\n",
    "\n",
    "        for line in fin:\n",
    "            parts = line.strip().split(' ||||| ')\n",
    "            if len(parts) >= 4:  # Check if there are at least 4 columns\n",
    "                year_str = parts[1]\n",
    "                if year_str.isdigit():\n",
    "                    year = int(year_str)\n",
    "                    # Update statistics\n",
    "                    stats[\"tokens\"] += len(parts[0].split())  # Assuming the tokens are in the first column\n",
    "                    stats[\"lines\"] += 1\n",
    "                    stats[\"min_year\"] = min(stats[\"min_year\"], year)\n",
    "                    stats[\"max_year\"] = max(stats[\"max_year\"], year)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def main():\n",
    "    # Your input files\n",
    "    input_files = [\n",
    "        \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/Psychology/abstract_year_journal.csv.mental\"\n",
    "    ]\n",
    "\n",
    "    # Process each corpus and store results\n",
    "    corpus_stats = []\n",
    "    for file_path in input_files:\n",
    "        stats = process_corpus(file_path, skip_header=True if \"Psychology\" in file_path else False)\n",
    "        if stats:\n",
    "            corpus_stats.append(stats)\n",
    "            print(f\"Corpus: {os.path.basename(file_path)}\")\n",
    "            print(f\"  Tokens: {stats['tokens']}\")\n",
    "            print(f\"  Lines: {stats['lines']}\")\n",
    "            print(f\"  Min Year: {stats['min_year']}\")\n",
    "            print(f\"  Max Year: {stats['max_year']}\\n\")\n",
    "\n",
    "    # Print or save corpus statistics (modify as needed)\n",
    "    os.makedirs(\"output\", exist_ok=True)  # Create the \"output\" folder if it doesn't exist\n",
    "\n",
    "    with open(os.path.join(\"output\", \"corpus_stats.all.txt\"), \"w\") as f:\n",
    "        for stats in corpus_stats:\n",
    "            f.write(f\"Tokens: {stats['tokens']}\\n\")\n",
    "            f.write(f\"Lines: {stats['lines']}\\n\")\n",
    "            f.write(f\"Min Year: {stats['min_year']}\\n\")\n",
    "            f.write(f\"Max Year: {stats['max_year']}\\n\\n\")\n",
    "\n",
    "    print(f\"Corpus statistics written to {os.path.join('output', 'corpus_stats.all.txt')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot corpus lines for each year for each corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year by Number of Abstracts (Old corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_counts\u001b[39m(file_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIIIII\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_counts(file_path, delimiter=\"IIIII\", skip_header=False):\n",
    "    \"\"\"\n",
    "    Extracts year-wise line counts from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file containing lines with year information.\n",
    "        delimiter (str): Delimiter separating year information (default is \"IIIII\").\n",
    "        skip_header (bool): Whether to skip the header line in the input file (default is False).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping years (integers) to their corresponding line counts (integers).\n",
    "    \"\"\"\n",
    "    counts_dict = {}\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            if skip_header:\n",
    "                next(file)  # Skip the header line (if applicable)\n",
    "\n",
    "            for line in file:\n",
    "                parts = line.strip().split(delimiter)\n",
    "\n",
    "                # Check if there are at least two elements after splitting\n",
    "                if len(parts) >= 2:\n",
    "                    # Extract the year from the second column\n",
    "                    year_str = parts[1].strip()\n",
    "                    # Check if the year is a valid digit within the specified range\n",
    "                    if year_str.isdigit():\n",
    "                        # Increment the count for the corresponding year\n",
    "                        year = int(year_str)\n",
    "                        counts_dict[year] = counts_dict.get(year, 0) + 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return counts_dict\n",
    "\n",
    "def process_files(input_files):\n",
    "    \"\"\"\n",
    "    Process each file and store year-wise counts.\n",
    "\n",
    "    Args:\n",
    "        input_files (dict): A dictionary mapping corpus names to their corresponding file paths.\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing year-wise counts for a corpus.\n",
    "    \"\"\"\n",
    "    corpus_counts = []\n",
    "    for corpus, file_path in input_files.items():\n",
    "        # Extract counts and append to corpus_counts\n",
    "        corpus_counts.append(extract_counts(file_path, delimiter=\"|||||\", skip_header=\"COHACOCA\" in corpus))\n",
    "        print(f\"File: {file_path}, Counts: {corpus_counts[-1]}\")\n",
    "    return corpus_counts\n",
    "\n",
    "def generate_plots(corpus_counts):\n",
    "    \"\"\"\n",
    "    Generate histograms of year-wise line counts.\n",
    "\n",
    "    Args:\n",
    "        corpus_counts (list): A list of dictionaries, each containing year-wise counts for a corpus.\n",
    "    \"\"\"\n",
    "    if not any(corpus_counts):\n",
    "        print(\"No data found in the provided files. Cannot generate plots.\")\n",
    "        return\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    fig, axs = plt.subplots(len(corpus_counts), figsize=(12, 6 * len(corpus_counts)))  # Create subplots for each corpus\n",
    "    \n",
    "    for i, corpus_count in enumerate(corpus_counts):\n",
    "        years = list(corpus_count.keys())\n",
    "        counts = list(corpus_count.values())\n",
    "\n",
    "        # Dynamically adjust the plotting range based on min and max years\n",
    "        min_year = min(years)\n",
    "        max_year = max(years)\n",
    "\n",
    "        axs[i].hist(years, bins=max_year - min_year + 1, weights=counts, range=(min_year, max_year), color='darkgrey', edgecolor='black')\n",
    "        axs[i].set_xlabel('Year')\n",
    "        axs[i].set_ylabel('Line Count')\n",
    "        axs[i].set_title(f'Year-wise Line Counts - Corpus {i+1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Your input files\n",
    "    input_files = {\n",
    "        #'cohacoca': \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/COHACOCA/coha.coca.cleaned2.lc.no-numb.noacad.mental\",\n",
    "        'psych': \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/Psychology/abstract_year_journal.csv.mental\"\n",
    "    }\n",
    "\n",
    "    corpus_counts = process_files(input_files)\n",
    "    generate_plots(corpus_counts)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year by number of sentences: Sentence corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 lines of the file:\n",
      "\n",
      "['The withdrawal response of the land snail helix albolabris disappears on appropriate repetition of the (mechanical) stimulus.', '1930']\n",
      "['In the usual terminology, the snail becomes habituated to the stimulus.', '1930']\n",
      "['The disappearance of the response cannot be due to fatigue, as this term is usually understood; for (a) a single stimulus may be sufficient to effect it, (b) more intense stimulation will, under conditions not quantitatively ascertained, remove the habituation, a fact difficult to reconcile with the ordinary conception of fatigue, (c) cases were observed where the habituation took longer to re-effect after the extraneous stimulus than before.', '1930']\n",
      "['Habituation disappears after appropriate rest.', '1930']\n",
      "['It may be deepened by further stimulation after response has ceased.', '1930']\n",
      "['The hypothesis is put forward of a physiological state or process tending to diminish action; such process would be intensified by appropriate repetition of the existing stimulus, and diminished by appropriate rest and extraneous stimulation.', '1930']\n",
      "['A similar hypothesis is made to explain the extinction of conditioned responses by Pavlov, who calls the underlying process Inhibition.', '1930']\n",
      "['The phenomenon investigated, and extinction of conditioned reflexes probably have the same explanation.', '1930']\n",
      "[\"With reference to the phenomena of habituation, the snail, as a biological system, behaves in the manner that would be expected of a system obeying Le Chatelier's rule.\", '1930']\n",
      "['In this section it is concluded that velocity is perceived directly and is dynamically conditioned by the structure and general properties of the visual field in which the movement occurs.', '1931']\n",
      "\n",
      "Statistics:\n",
      "Total number of lines (sentences): 5796467\n",
      "Min Year: 1930\n",
      "Max Year: 2019\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to the file you want to read\n",
    "input_file = 'C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/Psychology/abstract_year_journal.csv.mental.sentence-CLEAN.tsv'\n",
    "output_file_path = 'output/sentence_stats.txt'\n",
    "\n",
    "def read_first_10_lines_and_get_statistics(file_path, output_path):\n",
    "    min_year = float('inf')\n",
    "    max_year = float('-inf')\n",
    "    total_lines = 0\n",
    "\n",
    "    # Open the file and process the rows using csv.reader\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')  # Use tab as the delimiter\n",
    "        header = next(reader)  # Skip the header row if there is one\n",
    "\n",
    "        print(\"First 10 lines of the file:\\n\")\n",
    "        # Loop to process the file line by line\n",
    "        for index, row in enumerate(reader):\n",
    "            # Print the first 10 lines\n",
    "            if index < 10:\n",
    "                print(row)\n",
    "\n",
    "            # Track the year and total number of lines\n",
    "            try:\n",
    "                year = int(row[1].strip())  # Assuming the year is in the second column\n",
    "                min_year = min(min_year, year)\n",
    "                max_year = max(max_year, year)\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Invalid format in line {index+1}: {row}\")\n",
    "                continue\n",
    "\n",
    "            total_lines += 1\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"Total number of lines (sentences): {total_lines}\")\n",
    "    print(f\"Min Year: {min_year}\")\n",
    "    print(f\"Max Year: {max_year}\")\n",
    "\n",
    "    # Save statistics to a text file\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Ensure output directory exists\n",
    "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(\"Statistics:\\n\")\n",
    "        output_file.write(f\"Total number of lines (sentences): {total_lines}\\n\")\n",
    "        output_file.write(f\"Min Year: {min_year}\\n\")\n",
    "        output_file.write(f\"Max Year: {max_year}\\n\")\n",
    "\n",
    "# Call the function to process the file\n",
    "read_first_10_lines_and_get_statistics(input_file, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

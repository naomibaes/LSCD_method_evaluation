{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence length for synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentence lengths for abuse:\n",
      "baseline: 27.78 words\n",
      "positive_variation: 29.84 words\n",
      "negative_variation: 29.42 words\n",
      "Mean sentence lengths for anxiety:\n",
      "baseline: 26.76 words\n",
      "positive_variation: 27.69 words\n",
      "negative_variation: 27.55 words\n",
      "Mean sentence lengths for depression:\n",
      "baseline: 26.51 words\n",
      "positive_variation: 27.95 words\n",
      "negative_variation: 27.70 words\n",
      "Mean sentence lengths for mental_health:\n",
      "baseline: 28.25 words\n",
      "positive_variation: 28.72 words\n",
      "negative_variation: 28.74 words\n",
      "Mean sentence lengths for mental_illness:\n",
      "baseline: 27.77 words\n",
      "positive_variation: 28.43 words\n",
      "negative_variation: 28.51 words\n",
      "Mean sentence lengths for trauma:\n",
      "baseline: 27.90 words\n",
      "positive_variation: 30.46 words\n",
      "negative_variation: 30.05 words\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def mean_sentence_length(file_path):\n",
    "    # Initialize dictionaries to store total lengths and counts for each column\n",
    "    total_lengths = {}\n",
    "    total_sentences = {}\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        # Ensure the reader handles fields that might contain commas\n",
    "        reader = csv.reader(file, quotechar='\"')\n",
    "        headers = next(reader)  # Read the header to determine the columns\n",
    "\n",
    "        # Initialize the dictionaries based on the number of columns\n",
    "        for header in headers:\n",
    "            total_lengths[header] = 0\n",
    "            total_sentences[header] = 0\n",
    "\n",
    "        for row in reader:\n",
    "            for i, sentence in enumerate(row):\n",
    "                words = len(sentence.split())\n",
    "                total_lengths[headers[i]] += words\n",
    "                total_sentences[headers[i]] += 1\n",
    "\n",
    "    # Compute mean lengths for each column\n",
    "    mean_lengths = {header: (total_lengths[header] / total_sentences[header] if total_sentences[header] > 0 else 0) for header in headers}\n",
    "    return mean_lengths\n",
    "\n",
    "targets = ['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "\n",
    "# Example usage for multiple files\n",
    "base_path = '../1_sentiment/synthetic/output/all-year/'\n",
    "file_extension = '_synthetic_sentences.csv'\n",
    "\n",
    "for target in targets:\n",
    "    file_path = base_path + target + file_extension\n",
    "    mean_lengths = mean_sentence_length(file_path)\n",
    "    print(f\"Mean sentence lengths for {target}:\")\n",
    "    for column, length in mean_lengths.items():\n",
    "        print(f\"{column}: {length:.2f} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentence lengths for abuse:\n",
      "baseline: 27.77 words\n",
      "high_intensity: 29.62 words\n",
      "low_intensity: 29.18 words\n",
      "Mean sentence lengths for anxiety:\n",
      "baseline: 26.49 words\n",
      "high_intensity: 29.05 words\n",
      "low_intensity: 28.13 words\n",
      "Mean sentence lengths for depression:\n",
      "baseline: 26.85 words\n",
      "high_intensity: 29.88 words\n",
      "low_intensity: 29.11 words\n",
      "Mean sentence lengths for mental_health:\n",
      "baseline: 28.07 words\n",
      "high_intensity: 31.90 words\n",
      "low_intensity: 29.45 words\n",
      "Mean sentence lengths for mental_illness:\n",
      "baseline: 27.82 words\n",
      "high_intensity: 31.36 words\n",
      "low_intensity: 28.66 words\n",
      "Mean sentence lengths for trauma:\n",
      "baseline: 27.73 words\n",
      "high_intensity: 30.47 words\n",
      "low_intensity: 29.60 words\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def mean_sentence_length(file_path):\n",
    "    # Initialize dictionaries to store total lengths and counts for each column\n",
    "    total_lengths = {}\n",
    "    total_sentences = {}\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        # Ensure the reader handles fields that might contain commas\n",
    "        reader = csv.reader(file, quotechar='\"')\n",
    "        headers = next(reader)  # Read the header to determine the columns\n",
    "\n",
    "        # Initialize the dictionaries based on the number of columns\n",
    "        for header in headers:\n",
    "            total_lengths[header] = 0\n",
    "            total_sentences[header] = 0\n",
    "\n",
    "        for row in reader:\n",
    "            for i, sentence in enumerate(row):\n",
    "                words = len(sentence.split())\n",
    "                total_lengths[headers[i]] += words\n",
    "                total_sentences[headers[i]] += 1\n",
    "\n",
    "    # Compute mean lengths for each column\n",
    "    mean_lengths = {header: (total_lengths[header] / total_sentences[header] if total_sentences[header] > 0 else 0) for header in headers}\n",
    "    return mean_lengths\n",
    "\n",
    "targets = ['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "\n",
    "# Example usage for multiple files\n",
    "base_path = '../3_intensity/synthetic/output/all-year/'\n",
    "file_extension = '_synthetic_sentences.csv'\n",
    "\n",
    "for target in targets:\n",
    "    file_path = base_path + target + file_extension\n",
    "    mean_lengths = mean_sentence_length(file_path)\n",
    "    print(f\"Mean sentence lengths for {target}:\")\n",
    "    for column, length in mean_lengths.items():\n",
    "        print(f\"{column}: {length:.2f} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentence lengths for abuse:\n",
      "sentence: 27.22 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n",
      "Mean sentence lengths for anxiety:\n",
      "sentence: 26.38 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n",
      "Mean sentence lengths for depression:\n",
      "sentence: 26.62 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n",
      "Mean sentence lengths for mental_health:\n",
      "sentence: 26.12 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n",
      "Mean sentence lengths for mental_illness:\n",
      "sentence: 26.21 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n",
      "Mean sentence lengths for trauma:\n",
      "sentence: 26.34 words\n",
      "label: 1.00 words\n",
      "year: 1.00 words\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def mean_sentence_length(file_path):\n",
    "    # Initialize dictionaries to store total lengths and counts for each column\n",
    "    total_lengths = {}\n",
    "    total_sentences = {}\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        # Ensure the reader handles fields that might contain commas\n",
    "        reader = csv.reader(file, quotechar='\"')\n",
    "        headers = next(reader)  # Read the header to determine the columns\n",
    "\n",
    "        # Initialize the dictionaries based on the number of columns\n",
    "        for header in headers:\n",
    "            total_lengths[header] = 0\n",
    "            total_sentences[header] = 0\n",
    "\n",
    "        for row in reader:\n",
    "            for i, sentence in enumerate(row):\n",
    "                words = len(sentence.split())\n",
    "                total_lengths[headers[i]] += words\n",
    "                total_sentences[headers[i]] += 1\n",
    "\n",
    "    # Compute mean lengths for each column\n",
    "    mean_lengths = {header: (total_lengths[header] / total_sentences[header] if total_sentences[header] > 0 else 0) for header in headers}\n",
    "    return mean_lengths\n",
    "\n",
    "targets = ['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "\n",
    "# Example usage for multiple files\n",
    "base_path = '../2_breadth/synthetic/output/unique_all-year/'\n",
    "file_extension = '_synthetic_sentences.csv'\n",
    "\n",
    "for target in targets:\n",
    "    file_path = base_path + target + file_extension\n",
    "    mean_lengths = mean_sentence_length(file_path)\n",
    "    print(f\"Mean sentence lengths for {target}:\")\n",
    "    for column, length in mean_lengths.items():\n",
    "        print(f\"{column}: {length:.2f} words\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

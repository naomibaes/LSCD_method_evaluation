{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Intensity variations using LLMs\n",
    "\n",
    "Author: Raphael Merx (main) and Naomi Baes\n",
    "Input: a baseline sentence; Output: variations of this sentence where a target word is more or less intense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplemind python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import simplemind as sm\n",
    "from typing import Literal, List, get_args\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Define TARGET_WORD_CHOICES\n",
    "TARGET_WORD_CHOICES = Literal['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "TARGET_WORD: TARGET_WORD_CHOICES = 'abuse'\n",
    "\n",
    "# Generate human-readable versions for all target words\n",
    "TARGET_WORD_HUMAN_CHOICES = {word: word.replace('_', ' ') for word in get_args(TARGET_WORD_CHOICES)}\n",
    "TARGET_WORD_HUMAN = TARGET_WORD_HUMAN_CHOICES[TARGET_WORD]\n",
    "\n",
    "# Validate that both 'mental_health' and 'mental_illness' are handled correctly\n",
    "assert TARGET_WORD_HUMAN_CHOICES['mental_health'] == 'mental health', \"Error: 'mental_health' not handled correctly\"\n",
    "assert TARGET_WORD_HUMAN_CHOICES['mental_illness'] == 'mental illness', \"Error: 'mental_illness' not handled correctly\"\n",
    "\n",
    "# 1970-1974, ..., 2015-2019\n",
    "EPOCH_CHOICES = [f\"{y}-{y+4}\" for y in range(1970, 2020, 5)]\n",
    "EPOCH = EPOCH_CHOICES[0]\n",
    "\n",
    "MAX_BASELINES = 10\n",
    "\n",
    "# can be changed to gemini, see https://pypi.org/project/simplemind/\n",
    "PROVIDER = \"openai\"\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get neutral baseline sentences from corpus for LLM input for each target\n",
    "\n",
    "- **Script 1 Aim**: This script computes sentence-level sentiment scores using the NRC-VAD lexicon for a corpus of target terms spanning 1970–2019. It dynamically determines neutral sentiment ranges for each 5-year epoch by expanding outward from the median sentiment score within the interquartile range (Q1–Q3) until at least 500 sentences are included, capped at 1500. The selected sentences are saved to CSV files for each target and epoch, and a summary file logs the dynamic ranges and counts.\n",
    "\n",
    "- **Script 2 Aim**: This script processes pre-saved baseline CSV files to calculate sentence counts by year and 5-year epochs for multiple target terms. It generates \"year_count_lines.csv\" and \"epoch_count_lines.csv\" summarizing these counts and creates an epoch-based bar plot visualizing sentence distributions across the specified epochs for each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step0_get_neutral_baselines_intensity.py\n",
    "%run step1_plot_neutral_baselines_intensity.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup examples to inject in the prompt\n",
    "\n",
    "-This code sets up examples of baseline sentences and their intensity-modified variations (more and less intense) to provide context and guidance for the LLM. \n",
    "-These examples are formatted into a structured prompt to help the model understand how to generate intensity-modified variations for new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    baseline: str\n",
    "    more_intense: str\n",
    "    less_intense: str\n",
    "\n",
    "    def format_for_prompt(self):\n",
    "        return f\"\"\"<baseline>\n",
    "{self.baseline}\n",
    "</baseline>\n",
    "<increased {TARGET_WORD} intensity>\n",
    "{self.more_intense}\n",
    "</increased {TARGET_WORD} intensity>\n",
    "<decreased {TARGET_WORD} intensity>\n",
    "{self.less_intense}\n",
    "</decreased {TARGET_WORD} intensity>\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def read_example_data(word: TARGET_WORD_CHOICES) -> pd.DataFrame:\n",
    "        filepath = os.path.join('input', f'intensity_example_sentences.xlsx')\n",
    "        # read to a dataframe\n",
    "        df = pd.read_excel(filepath)\n",
    "        # filter rows where `target` column is equal to the `word` argument\n",
    "        df = df[df['target'] == word]\n",
    "        return df\n",
    "\n",
    "def get_examples() -> List[Example]:\n",
    "    example_data = Example.read_example_data(TARGET_WORD)\n",
    "\n",
    "    return [\n",
    "        Example(\n",
    "            baseline=row['baseline'],\n",
    "            more_intense=row['high_intensity'],\n",
    "            less_intense=row['low_intensity']\n",
    "        )\n",
    "        for _, row in example_data.iterrows()\n",
    "    ]\n",
    "\n",
    "PROMPT_INTRO = \"\"\"In psychology research, Intensity is defined as “the degree to which a word has emotionally charged (i.e., strong, potent, high-arousal) connotations.” This task focuses on the intensity of the term **<<{target_word}>>**. \n",
    "\n",
    "### **Task**  \n",
    "You will be given a sentence containing the term **<<{target_word}>>**. Your goal is to write two new sentences:\n",
    "1. One where **<<{target_word}>>** is **less intense**.  \n",
    "2. One where **<<{target_word}>>** is **more intense**.  \n",
    "\n",
    "### **Rules**  \n",
    "1. The term **<<{target_word}>>** must remain **exactly as it appears** in the original sentence:\n",
    "   - Do **not** replace, rephrase, omit, or modify it in any way.\n",
    "   - Synonyms, variations, or altered spellings are not allowed.  \n",
    "\n",
    "2. **Meaning and Structure**:  \n",
    "   - Stay true to the original context and subject matter.  \n",
    "   - Maintain the sentence’s structure and ensure grammatical accuracy.  \n",
    "\n",
    "### **Important**  \n",
    "- Any response omitting, replacing, or altering **<<{target_word}>>** will be rejected.  \n",
    "- Ensure the output is:  \n",
    "   - **Grammatically correct**  \n",
    "   - **Sensitive and serious** in tone  \n",
    "   - **Free from exaggeration or sensationalism**  \n",
    "\n",
    "Follow these guidelines strictly to produce valid responses.  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SentenceToModify:\n",
    "    text: str\n",
    "    increased_variation: str = None\n",
    "    decreased_variation: str = None\n",
    "\n",
    "    def get_prompt(self):\n",
    "        prompt = PROMPT_INTRO.format(target_word=TARGET_WORD) + \"\\n\\n\"\n",
    "        for example in get_examples():\n",
    "            prompt += example.format_for_prompt()\n",
    "            prompt += \"\\n\\n\"\n",
    "        \n",
    "        prompt += f\"\"\"<baseline>\n",
    "{self.text}\n",
    "</baseline>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def parse_response(self, response: str):\n",
    "        # get the sentences inside <more {TARGET_WORD}> and <less {TARGET_WORD}>\n",
    "        try:\n",
    "            self.increased_variation = response.split(f\"<increased {TARGET_WORD} intensity>\")[1].split(f\"</increased {TARGET_WORD} intensity>\")[0].strip()\n",
    "            self.decreased_variation = response.split(f\"<decreased {TARGET_WORD} intensity>\")[1].split(f\"</decreased {TARGET_WORD} intensity>\")[0].strip()\n",
    "        except IndexError:\n",
    "            raise ValueError(f\"LLM response does not contain the expected format: {response}\")\n",
    "        return self.increased_variation, self.decreased_variation\n",
    "\n",
    "    def get_variations(self) -> list[str]:\n",
    "        \"\"\" Returns a list of two strings: one where the TARGET_WORD is more intense, and one where it is less intense \"\"\"\n",
    "        assert TARGET_WORD in self.text.lower(), f\"word {TARGET_WORD} not found in {self.text}\"\n",
    "        prompt = self.get_prompt()\n",
    "        res = sm.generate_text(prompt=prompt, llm_provider=PROVIDER, llm_model=MODEL)\n",
    "        return self.parse_response(res)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_baselines(word: TARGET_WORD_CHOICES, epoch: EPOCH_CHOICES) -> List[str]:\n",
    "        # find the baselines.csv file in the `input` folder\n",
    "        filepath = os.path.join('input', 'baselines', f'{word}_{epoch}.baseline_1500_sentences.csv')\n",
    "        df = pd.read_csv(filepath)\n",
    "        # return the `sentence` column as a list\n",
    "        print(f\"Word {word}, epoch {epoch}: \", end=\"\")\n",
    "        print(f\"Loaded {len(df)} baseline sentences, sampling {MAX_BASELINES}\")\n",
    "        baselines = df['sentence'].tolist()\n",
    "        if MAX_BASELINES and len(baselines) > MAX_BASELINES:\n",
    "            baselines = random.sample(baselines, MAX_BASELINES)\n",
    "        baselines = [s.replace(TARGET_WORD, TARGET_WORD) for s in baselines]\n",
    "        return baselines\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_sentences(sentences: List['SentenceToModify'], word: TARGET_WORD_CHOICES, epoch: EPOCH_CHOICES):\n",
    "        # Adjust the directory here to include 'test'\n",
    "        output_dir = 'output/test'\n",
    "        output_file = os.path.join(output_dir, f'{word}_{epoch}.synthetic_sentences.csv')\n",
    "        \n",
    "        # Ensure the directory exists before trying to write to it\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Creating DataFrame and saving to CSV\n",
    "        df = pd.DataFrame([{'baseline': s.text, 'high_intensity': s.increased_variation, 'low_intensity': s.decreased_variation} for s in sentences])\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {len(sentences)} sentences to {output_file}\")\n",
    "\n",
    "baselines = SentenceToModify.load_baselines(TARGET_WORD, EPOCH)\n",
    "sentence = SentenceToModify(text=baselines[0])\n",
    "print(sentence.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if output/test/abuse_2015-2019.synthetic_sentences.csv exists...\n",
      "Word abuse, epoch 2015-2019: Loaded 1079 baseline sentences, sampling 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 sentences to output/test/abuse_2015-2019.synthetic_sentences.csv\n",
      "Processed and saved: output/test/abuse_2015-2019.synthetic_sentences.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants for processing\n",
    "MAX_BASELINES = 10\n",
    "OUTPUT_DIR = \"output/test\"  # Directory where processed files are saved\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Loop through each target word and epoch\n",
    "for TARGET_WORD in get_args(TARGET_WORD_CHOICES):\n",
    "    for EPOCH in EPOCH_CHOICES:\n",
    "        # Construct the file path to check if it already exists\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{TARGET_WORD}_{EPOCH}.synthetic_sentences.csv\")\n",
    "\n",
    "        # Print the file path to debug\n",
    "        print(f\"Checking if {output_file} exists...\")\n",
    "\n",
    "        # Skip if the file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {TARGET_WORD}, {EPOCH}: File already processed.\")\n",
    "            continue\n",
    "\n",
    "        # Load baselines if the file does not exist\n",
    "        baselines = SentenceToModify.load_baselines(TARGET_WORD, EPOCH)\n",
    "        sentences = []\n",
    "\n",
    "        # Process each baseline sentence\n",
    "        for baseline in tqdm(baselines, total=len(baselines), unit='it', leave=True):\n",
    "            sentence = SentenceToModify(text=baseline)\n",
    "            try:\n",
    "                more_intense_variation, less_intense_variation = sentence.get_variations()\n",
    "                sentences.append(sentence)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sentence: {baseline}. Error: {str(e)}\")\n",
    "\n",
    "        # Save the processed sentences\n",
    "        if sentences:  # Only save if there are completed sentences\n",
    "            SentenceToModify.save_sentences(sentences, word=TARGET_WORD, epoch=EPOCH)\n",
    "            print(f\"Processed and saved: {output_file}\")\n",
    "        else:\n",
    "            print(f\"No valid sentences processed for {TARGET_WORD}, {EPOCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

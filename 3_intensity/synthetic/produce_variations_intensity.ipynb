{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Intensity variations using LLMs\n",
    "\n",
    "Author: Raphael Merx (main) and Naomi Baes\n",
    "Input: a baseline sentence; Output: variations of this sentence where a target word is more or less intense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplemind python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import simplemind as sm\n",
    "from typing import Literal, List, get_args\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Define TARGET_WORD_CHOICES\n",
    "TARGET_WORD_CHOICES = Literal['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "TARGET_WORD: TARGET_WORD_CHOICES = 'abuse'\n",
    "\n",
    "# Generate human-readable versions for all target words\n",
    "TARGET_WORD_HUMAN_CHOICES = {word: word.replace('_', ' ') for word in get_args(TARGET_WORD_CHOICES)}\n",
    "TARGET_WORD_HUMAN = TARGET_WORD_HUMAN_CHOICES[TARGET_WORD]\n",
    "\n",
    "# Validate that both 'mental_health' and 'mental_illness' are handled correctly\n",
    "assert TARGET_WORD_HUMAN_CHOICES['mental_health'] == 'mental health', \"Error: 'mental_health' not handled correctly\"\n",
    "assert TARGET_WORD_HUMAN_CHOICES['mental_illness'] == 'mental illness', \"Error: 'mental_illness' not handled correctly\"\n",
    "\n",
    "# 1970-1974, ..., 2015-2019\n",
    "EPOCH_CHOICES = [f\"{y}-{y+4}\" for y in range(1970, 2020, 5)]\n",
    "EPOCH = EPOCH_CHOICES[0]\n",
    "\n",
    "MAX_BASELINES = 10\n",
    "\n",
    "# can be changed to gemini, see https://pypi.org/project/simplemind/\n",
    "PROVIDER = \"openai\"\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get neutral baseline sentences from corpus for LLM input for each target\n",
    "\n",
    "- **Script 1 Aim**: This script computes sentence-level sentiment scores using the NRC-VAD lexicon for a corpus of target terms spanning 1970–2019. It dynamically determines neutral sentiment ranges for each 5-year epoch by expanding outward from the median sentiment score within the interquartile range (Q1–Q3) until at least 500 sentences are included, capped at 1500. The selected sentences are saved to CSV files for each target and epoch, and a summary file logs the dynamic ranges and counts.\n",
    "\n",
    "- **Script 2 Aim**: This script processes pre-saved baseline CSV files to calculate sentence counts by year and 5-year epochs for multiple target terms. It generates \"year_count_lines.csv\" and \"epoch_count_lines.csv\" summarizing these counts and creates an epoch-based bar plot visualizing sentence distributions across the specified epochs for each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step0_get_neutral_baselines_intensity.py\n",
    "%run step1_plot_neutral_baselines_intensity.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup examples to inject in the prompt\n",
    "\n",
    "-This code sets up examples of baseline sentences and their intensity-modified variations (more and less intense) to provide context and guidance for the LLM. \n",
    "-These examples are formatted into a structured prompt to help the model understand how to generate intensity-modified variations for new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    baseline: str\n",
    "    more_intense: str\n",
    "    less_intense: str\n",
    "\n",
    "    def format_for_prompt(self):\n",
    "        return f\"\"\"<baseline>\n",
    "{self.baseline}\n",
    "</baseline>\n",
    "<increased {TARGET_WORD} intensity>\n",
    "{self.more_intense}\n",
    "</increased {TARGET_WORD} intensity>\n",
    "<decreased {TARGET_WORD} intensity>\n",
    "{self.less_intense}\n",
    "</decreased {TARGET_WORD} intensity>\n",
    "\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def read_example_data(word: TARGET_WORD_CHOICES) -> pd.DataFrame:\n",
    "        filepath = os.path.join('input', f'intensity_example_sentences.xlsx')\n",
    "        # read to a dataframe\n",
    "        df = pd.read_excel(filepath)\n",
    "        # filter rows where `target` column is equal to the `word` argument\n",
    "        df = df[df['target'] == word]\n",
    "        print(f\"Loaded {len(df)} examples for the term '{word}'\")\n",
    "        return df\n",
    "\n",
    "def get_examples() -> List[Example]:\n",
    "    example_data = Example.read_example_data(TARGET_WORD)\n",
    "\n",
    "    return [\n",
    "        Example(\n",
    "            baseline=row['baseline'],\n",
    "            more_intense=row['high_intensity'],\n",
    "            less_intense=row['low_intensity']\n",
    "        )\n",
    "        for _, row in example_data.iterrows()\n",
    "    ]\n",
    "\n",
    "PROMPT_INTRO = \"\"\"In psychology research, Intensity is defined as “the degree to which a word has emotionally charged (i.e., strong, potent, high-arousal) connotations.” This task focuses on the intensity of the term **<<{target_word}>>**. \n",
    "\n",
    "### **Task**  \n",
    "You will be given a sentence containing the term **<<{target_word}>>**. Your goal is to write two new sentences:\n",
    "1. One where **<<{target_word}>>** is **less intense**.  \n",
    "2. One where **<<{target_word}>>** is **more intense**.  \n",
    "\n",
    "### **Rules**  \n",
    "1. The term **<<{target_word}>>** must remain **exactly as it appears** in the original sentence:\n",
    "   - Do **not** replace, rephrase, omit, or modify it in any way.\n",
    "   - Synonyms, variations, or altered spellings are not allowed.  \n",
    "\n",
    "2. **Meaning and Structure**:  \n",
    "   - Stay true to the original context and subject matter.  \n",
    "   - Maintain the sentence’s structure and ensure grammatical accuracy.  \n",
    "\n",
    "### **Important**  \n",
    "- Any response omitting, replacing, or altering **<<{target_word}>>** will be rejected.  \n",
    "- Ensure the output is:  \n",
    "   - **Grammatically correct**  \n",
    "   - **Sensitive and serious** in tone  \n",
    "   - **Free from exaggeration or sensationalism**  \n",
    "\n",
    "Follow these guidelines strictly to produce valid responses.  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word abuse, epoch 1970-1974: Loaded 13 baseline sentences, sampling 10\n",
      "Loaded 5 examples for the term 'abuse'\n",
      "In psychology research, Intensity is defined as “the degree to which a word has emotionally charged (i.e., strong, potent, high-arousal) connotations.” This task focuses on the intensity of the term **<<abuse>>**. \n",
      "\n",
      "### **Task**  \n",
      "You will be given a sentence containing the term **<<abuse>>**. Your goal is to write two new sentences:\n",
      "1. One where **<<abuse>>** is **less intense**.  \n",
      "2. One where **<<abuse>>** is **more intense**.  \n",
      "\n",
      "### **Rules**  \n",
      "1. The term **<<abuse>>** must remain **exactly as it appears** in the original sentence:\n",
      "   - Do **not** replace, rephrase, omit, or modify it in any way.\n",
      "   - Synonyms, variations, or altered spellings are not allowed.  \n",
      "\n",
      "2. **Meaning and Structure**:  \n",
      "   - Stay true to the original context and subject matter.  \n",
      "   - Maintain the sentence’s structure and ensure grammatical accuracy.  \n",
      "\n",
      "### **Important**  \n",
      "- Any response omitting, replacing, or altering **<<abuse>>** will be rejected.  \n",
      "- Ensure the output is:  \n",
      "   - **Grammatically correct**  \n",
      "   - **Sensitive and serious** in tone  \n",
      "   - **Free from exaggeration or sensationalism**  \n",
      "\n",
      "Follow these guidelines strictly to produce valid responses.  \n",
      "\n",
      "\n",
      "<baseline>\n",
      "Clinically, however, individual questions that use broad labeling terms are more likely to identify women as having a history of abuse.\n",
      "</baseline>\n",
      "<increased abuse intensity>\n",
      "Clinically, however, individual questions that use extreme labeling terms are more likely to reveal women as having a severe history of abuse.\n",
      "</increased abuse intensity>\n",
      "<decreased abuse intensity>\n",
      "Clinically, however, individual questions that use broad labeling terms are more likely to identify women as having a mild history of abuse.\n",
      "</decreased abuse intensity>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "Most care workers said that they would be willing to report abuse anonymously.\n",
      "</baseline>\n",
      "<increased abuse intensity>\n",
      "Most care workers cried that they would be delighted to report extreme instances of abuse anonymously.\n",
      "</increased abuse intensity>\n",
      "<decreased abuse intensity>\n",
      "Most care workers said that they would be willing to report trivial abuse anonymously.\n",
      "</decreased abuse intensity>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "There is greater emphasis on recognizing that older people may be subjected to abuse and neglect by family members and the community as well.\n",
      "</baseline>\n",
      "<increased abuse intensity>\n",
      "There is a significant emphasis on recognizing that older people may be subjected to severe abuse and appalling neglect by family members and the community as well.\n",
      "</increased abuse intensity>\n",
      "<decreased abuse intensity>\n",
      "There is some emphasis on recognizing that older people may experience weak abuse by family members and the community as well.\n",
      "</decreased abuse intensity>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "Education on financial abuse for both elders and their adult children and establishment of income support programs are urgently needed.\n",
      "</baseline>\n",
      "<increased abuse intensity>\n",
      "Education on ordinary financial abuse for both elders and their adult children and urgent establishment of income support programs are desperately needed.\n",
      "</increased abuse intensity>\n",
      "<decreased abuse intensity>\n",
      "Education on financial abuse for both elders and their adult children and establishment of income support programs will occur.\n",
      "</decreased abuse intensity>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "There was no association between physical abuse and depressive symptoms through either self-compassion or gratitude.\n",
      "</baseline>\n",
      "<increased abuse intensity>\n",
      "There was no association between frightening physical abuse and cold symptoms through either emotional contagion or extreme gratitude.\n",
      "</increased abuse intensity>\n",
      "<decreased abuse intensity>\n",
      "There was no association between mild physical abuse and state of mind through either complacency or gratitude.\n",
      "</decreased abuse intensity>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "To determine the availability of effective reinforcers of activity which could be delivered in an outpatient drug abuse clinic, a survey was administered to 25 Methadone maintenance patients.\n",
      "</baseline>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SentenceToModify:\n",
    "    text: str\n",
    "    increased_variation: str = None\n",
    "    decreased_variation: str = None\n",
    "\n",
    "    def get_prompt(self):\n",
    "        prompt = PROMPT_INTRO.format(target_word=TARGET_WORD) + \"\\n\\n\"\n",
    "        for example in get_examples():\n",
    "            prompt += example.format_for_prompt()\n",
    "            prompt += \"\\n\\n\"\n",
    "        \n",
    "        prompt += f\"\"\"<baseline>\n",
    "{self.text}\n",
    "</baseline>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def parse_response(self, response: str):\n",
    "        # get the sentences inside <more {TARGET_WORD}> and <less {TARGET_WORD}>\n",
    "        self.increased_variation = response.split(f\"<increased {TARGET_WORD} intensity>\")[1].split(f\"</increased {TARGET_WORD} intensity>\")[0].strip()\n",
    "        self.decreased_variation = response.split(f\"<decreased {TARGET_WORD} intensity>\")[1].split(f\"</decreased {TARGET_WORD} intensity>\")[0].strip()\n",
    "        return self.increased_variation, self.decreased_variation\n",
    "\n",
    "    def get_variations(self) -> list[str]:\n",
    "        \"\"\" Returns a list of two strings: one where the TARGET_WORD is more intense, and one where it is less intense \"\"\"\n",
    "        assert TARGET_WORD in self.text, f\"word {TARGET_WORD} not found in {self.text}\"\n",
    "        prompt = self.get_prompt()\n",
    "        res = sm.generate_text(prompt=prompt, llm_provider=PROVIDER, llm_model=MODEL)\n",
    "        return self.parse_response(res)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_baselines(word: TARGET_WORD_CHOICES, epoch: EPOCH_CHOICES) -> List[str]:\n",
    "        # find the baselines.csv file in the `input` folder\n",
    "        filepath = os.path.join('input', 'baselines', f'{word}_{epoch}.baseline_1500_sentences.csv')\n",
    "        df = pd.read_csv(filepath)\n",
    "        # return the `sentence` column as a list\n",
    "        print(f\"Word {word}, epoch {epoch}: \", end=\"\")\n",
    "        print(f\"Loaded {len(df)} baseline sentences, sampling {MAX_BASELINES}\")\n",
    "        baselines = df['sentence'].tolist()\n",
    "        if MAX_BASELINES and len(baselines) > MAX_BASELINES:\n",
    "            baselines = random.sample(baselines, MAX_BASELINES)\n",
    "        baselines = [s.replace(TARGET_WORD, TARGET_WORD) for s in baselines]\n",
    "        return baselines\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_sentences(sentences: List['SentenceToModify'], word: TARGET_WORD_CHOICES, epoch: EPOCH_CHOICES):\n",
    "        # Adjust the directory here to include 'test'\n",
    "        output_dir = 'output/test'\n",
    "        output_file = os.path.join(output_dir, f'{word}_{epoch}.synthetic_sentences.csv')\n",
    "        \n",
    "        # Ensure the directory exists before trying to write to it\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Creating DataFrame and saving to CSV\n",
    "        df = pd.DataFrame([{'baseline': s.text, 'high_intensity': s.increased_variation, 'low_intensity': s.decreased_variation} for s in sentences])\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {len(sentences)} sentences to {output_file}\")\n",
    "\n",
    "baselines = SentenceToModify.load_baselines(TARGET_WORD, EPOCH)\n",
    "sentence = SentenceToModify(text=baselines[0])\n",
    "print(sentence.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if output/test/abuse_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1970-1974: File already processed.\n",
      "Checking if output/test/abuse_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1975-1979: File already processed.\n",
      "Checking if output/test/abuse_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1980-1984: File already processed.\n",
      "Checking if output/test/abuse_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1985-1989: File already processed.\n",
      "Checking if output/test/abuse_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1990-1994: File already processed.\n",
      "Checking if output/test/abuse_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 1995-1999: File already processed.\n",
      "Checking if output/test/abuse_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 2000-2004: File already processed.\n",
      "Checking if output/test/abuse_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 2005-2009: File already processed.\n",
      "Checking if output/test/abuse_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 2010-2014: File already processed.\n",
      "Checking if output/test/abuse_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping abuse, 2015-2019: File already processed.\n",
      "Checking if output/test/anxiety_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1970-1974: File already processed.\n",
      "Checking if output/test/anxiety_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1975-1979: File already processed.\n",
      "Checking if output/test/anxiety_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1980-1984: File already processed.\n",
      "Checking if output/test/anxiety_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1985-1989: File already processed.\n",
      "Checking if output/test/anxiety_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1990-1994: File already processed.\n",
      "Checking if output/test/anxiety_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 1995-1999: File already processed.\n",
      "Checking if output/test/anxiety_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 2000-2004: File already processed.\n",
      "Checking if output/test/anxiety_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 2005-2009: File already processed.\n",
      "Checking if output/test/anxiety_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 2010-2014: File already processed.\n",
      "Checking if output/test/anxiety_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping anxiety, 2015-2019: File already processed.\n",
      "Checking if output/test/depression_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1970-1974: File already processed.\n",
      "Checking if output/test/depression_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1975-1979: File already processed.\n",
      "Checking if output/test/depression_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1980-1984: File already processed.\n",
      "Checking if output/test/depression_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1985-1989: File already processed.\n",
      "Checking if output/test/depression_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1990-1994: File already processed.\n",
      "Checking if output/test/depression_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping depression, 1995-1999: File already processed.\n",
      "Checking if output/test/depression_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping depression, 2000-2004: File already processed.\n",
      "Checking if output/test/depression_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping depression, 2005-2009: File already processed.\n",
      "Checking if output/test/depression_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping depression, 2010-2014: File already processed.\n",
      "Checking if output/test/depression_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping depression, 2015-2019: File already processed.\n",
      "Checking if output/test/mental_health_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1970-1974: File already processed.\n",
      "Checking if output/test/mental_health_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1975-1979: File already processed.\n",
      "Checking if output/test/mental_health_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1980-1984: File already processed.\n",
      "Checking if output/test/mental_health_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1985-1989: File already processed.\n",
      "Checking if output/test/mental_health_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1990-1994: File already processed.\n",
      "Checking if output/test/mental_health_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 1995-1999: File already processed.\n",
      "Checking if output/test/mental_health_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 2000-2004: File already processed.\n",
      "Checking if output/test/mental_health_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 2005-2009: File already processed.\n",
      "Checking if output/test/mental_health_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 2010-2014: File already processed.\n",
      "Checking if output/test/mental_health_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping mental_health, 2015-2019: File already processed.\n",
      "Checking if output/test/mental_illness_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1970-1974: File already processed.\n",
      "Checking if output/test/mental_illness_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1975-1979: File already processed.\n",
      "Checking if output/test/mental_illness_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1980-1984: File already processed.\n",
      "Checking if output/test/mental_illness_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1985-1989: File already processed.\n",
      "Checking if output/test/mental_illness_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1990-1994: File already processed.\n",
      "Checking if output/test/mental_illness_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 1995-1999: File already processed.\n",
      "Checking if output/test/mental_illness_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 2000-2004: File already processed.\n",
      "Checking if output/test/mental_illness_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 2005-2009: File already processed.\n",
      "Checking if output/test/mental_illness_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 2010-2014: File already processed.\n",
      "Checking if output/test/mental_illness_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping mental_illness, 2015-2019: File already processed.\n",
      "Checking if output/test/trauma_1970-1974.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1970-1974: File already processed.\n",
      "Checking if output/test/trauma_1975-1979.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1975-1979: File already processed.\n",
      "Checking if output/test/trauma_1980-1984.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1980-1984: File already processed.\n",
      "Checking if output/test/trauma_1985-1989.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1985-1989: File already processed.\n",
      "Checking if output/test/trauma_1990-1994.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1990-1994: File already processed.\n",
      "Checking if output/test/trauma_1995-1999.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 1995-1999: File already processed.\n",
      "Checking if output/test/trauma_2000-2004.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 2000-2004: File already processed.\n",
      "Checking if output/test/trauma_2005-2009.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 2005-2009: File already processed.\n",
      "Checking if output/test/trauma_2010-2014.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 2010-2014: File already processed.\n",
      "Checking if output/test/trauma_2015-2019.synthetic_sentences.csv exists...\n",
      "Skipping trauma, 2015-2019: File already processed.\n"
     ]
    }
   ],
   "source": [
    "# Constants for processing\n",
    "MAX_BASELINES = 10\n",
    "OUTPUT_DIR = \"output/test\"  # Directory where processed files are saved\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Loop through each target word and epoch\n",
    "for TARGET_WORD in get_args(TARGET_WORD_CHOICES):\n",
    "    for EPOCH in EPOCH_CHOICES:\n",
    "        # Construct the file path to check if it already exists\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{TARGET_WORD}_{EPOCH}.synthetic_sentences.csv\")\n",
    "        \n",
    "        # Print the file path to debug\n",
    "        print(f\"Checking if {output_file} exists...\")\n",
    "        \n",
    "        # Skip if the file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {TARGET_WORD}, {EPOCH}: File already processed.\")\n",
    "            continue\n",
    "        \n",
    "        # Load baselines if the file does not exist\n",
    "        baselines = SentenceToModify.load_baselines(TARGET_WORD, EPOCH)\n",
    "        sentences = []\n",
    "        \n",
    "        # Process each baseline sentence\n",
    "        for baseline in tqdm(baselines):\n",
    "            sentence = SentenceToModify(text=baseline)\n",
    "            try:\n",
    "                more_intense_variation, less_intense_variation = sentence.get_variations()\n",
    "                sentences.append(sentence)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sentence: {baseline}. Error: {str(e)}\")\n",
    "        \n",
    "        # Save the processed sentences\n",
    "        if sentences:  # Only save if there are completed sentences\n",
    "            SentenceToModify.save_sentences(sentences, word=TARGET_WORD, epoch=EPOCH)\n",
    "            print(f\"Processed and saved: {output_file}\")\n",
    "        else:\n",
    "            print(f\"No valid sentences processed for {TARGET_WORD}, {EPOCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

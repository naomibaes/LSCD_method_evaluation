{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Sentiment variations using LLMs\n",
    "\n",
    "Author: Raphael Merx\n",
    "Input: a baseline sentence; Output: variations of this sentence where a target word is more or less intense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplemind\n",
      "  Downloading simplemind-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting instructor (from simplemind)\n",
      "  Downloading instructor-1.6.4-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting logfire (from simplemind)\n",
      "  Downloading logfire-2.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: pydantic in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from simplemind) (2.3.0)\n",
      "Collecting pydantic-settings (from simplemind)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor->simplemind)\n",
      "  Downloading aiohttp-3.11.7-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting docstring-parser<0.17,>=0.16 (from instructor->simplemind)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.4 (from instructor->simplemind)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jiter<0.7,>=0.6.1 (from instructor->simplemind)\n",
      "  Downloading jiter-0.6.1-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting openai<2.0.0,>=1.52.0 (from instructor->simplemind)\n",
      "  Downloading openai-1.55.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pydantic (from simplemind)\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "     ---------------------------------------- 0.0/170.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 170.8/170.8 kB 10.0 MB/s eta 0:00:00\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor->simplemind)\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from instructor->simplemind) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from instructor->simplemind) (13.7.1)\n",
      "Collecting tenacity<10.0.0,>=9.0.0 (from instructor->simplemind)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from instructor->simplemind) (0.9.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->simplemind)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic->simplemind)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting executing>=2.0.1 (from logfire->simplemind)\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.21.0 (from logfire->simplemind)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation>=0.41b0 (from logfire->simplemind)\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.21.0 (from logfire->simplemind)\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf>=4.23.4 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from logfire->simplemind) (5.28.3)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind) (6.0.2)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind)\n",
      "  Using cached propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.1->instructor->simplemind)\n",
      "  Downloading yarl-1.18.0-cp311-cp311-win_amd64.whl.metadata (69 kB)\n",
      "     ---------------------------------------- 0.0/69.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 69.9/69.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->simplemind) (2.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor->simplemind) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor->simplemind) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor->simplemind) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor->simplemind) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor->simplemind) (4.65.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api~=1.15 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind)\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation>=0.41b0->logfire->simplemind)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation>=0.41b0->logfire->simplemind) (23.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation>=0.41b0->logfire->simplemind) (1.14.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor->simplemind) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor->simplemind) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor->simplemind) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor->simplemind) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.7.0->instructor->simplemind) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.7.0->instructor->simplemind) (2.15.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor->simplemind) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<1.0.0,>=0.9.0->instructor->simplemind) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor->simplemind) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor->simplemind) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->simplemind) (0.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire->simplemind) (3.11.0)\n",
      "Downloading simplemind-0.2.4-py3-none-any.whl (25 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading instructor-1.6.4-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.1/70.1 kB ? eta 0:00:00\n",
      "Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "   ---------------------------------------- 0.0/456.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 456.4/456.4 kB 29.7 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/2.0 MB 28.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 28.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 25.3 MB/s eta 0:00:00\n",
      "Downloading logfire-2.4.1-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/171.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 171.2/171.2 kB ? eta 0:00:00\n",
      "Using cached pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading aiohttp-3.11.7-cp311-cp311-win_amd64.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 440.9/440.9 kB 28.7 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading jiter-0.6.1-cp311-none-win_amd64.whl (201 kB)\n",
      "   ---------------------------------------- 0.0/202.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 202.0/202.0 kB ? eta 0:00:00\n",
      "Downloading openai-1.55.1-py3-none-any.whl (389 kB)\n",
      "   ---------------------------------------- 0.0/389.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 389.5/389.5 kB 23.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.8/55.8 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 159.2/159.2 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.3/64.3 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "   ---------------------------------------- 0.0/118.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 118.8/118.8 kB ? eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 221.7/221.7 kB 13.2 MB/s eta 0:00:00\n",
      "Using cached propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.0-cp311-cp311-win_amd64.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.8/90.8 kB ? eta 0:00:00\n",
      "Installing collected packages: typing-extensions, tenacity, python-dotenv, propcache, opentelemetry-proto, jiter, jinja2, googleapis-common-protos, executing, docstring-parser, deprecated, annotated-types, aiohappyeyeballs, yarl, pydantic-core, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, pydantic, opentelemetry-semantic-conventions, aiohttp, pydantic-settings, opentelemetry-sdk, opentelemetry-instrumentation, openai, opentelemetry-exporter-otlp-proto-http, instructor, logfire, simplemind\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 0.8.3\n",
      "    Uninstalling executing-0.8.3:\n",
      "      Successfully uninstalled executing-0.8.3\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.5.0\n",
      "    Uninstalling annotated-types-0.5.0:\n",
      "      Successfully uninstalled annotated-types-0.5.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.8.1\n",
      "    Uninstalling yarl-1.8.1:\n",
      "      Successfully uninstalled yarl-1.8.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.6.3\n",
      "    Uninstalling pydantic_core-2.6.3:\n",
      "      Successfully uninstalled pydantic_core-2.6.3\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.3.0\n",
      "    Uninstalling pydantic-2.3.0:\n",
      "      Successfully uninstalled pydantic-2.3.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.3\n",
      "    Uninstalling aiohttp-3.8.3:\n",
      "      Successfully uninstalled aiohttp-3.8.3\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 annotated-types-0.7.0 deprecated-1.2.15 docstring-parser-0.16 executing-2.1.0 googleapis-common-protos-1.66.0 instructor-1.6.4 jinja2-3.1.4 jiter-0.6.1 logfire-2.4.1 openai-1.55.1 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-http-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 propcache-0.2.0 pydantic-2.10.2 pydantic-core-2.27.1 pydantic-settings-2.6.1 python-dotenv-1.0.1 simplemind-0.2.4 tenacity-9.0.0 typing-extensions-4.12.2 yarl-1.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy-transformers 1.2.5 requires transformers<4.31.0,>=3.4.0, but you have transformers 4.40.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#pip install simplemind python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import simplemind as sm\n",
    "\n",
    "TARGET_WORD = 'anxiety'\n",
    "#TARGET_WORDS = ['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "\n",
    "# can be changed to gemini, see https://pypi.org/project/simplemind/\n",
    "PROVIDER = \"openai\"\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get neutral sentences from corpus for LLM input for each target\n",
    "\n",
    "**Aim**: This script processes text files containing sentences for specified target terms, calculates sentence-level mean arousal scores using the NRC-VAD lexicon, identifies \n",
    "sentences with neutral arousal scores (dynamically globally determined from NRC-VAD dataset), and saves these sentences along with their metadata to output files in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic neutral arousal range: (0.47, 0.49)\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\abuse.lines.psych\n",
      "Saved neutral arousal sentences for abuse to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\abuse_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for abuse: 4262\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\anxiety.lines.psych\n",
      "Saved neutral arousal sentences for anxiety to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\anxiety_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for anxiety: 12318\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\depression.lines.psych\n",
      "Saved neutral arousal sentences for depression to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\depression_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for depression: 15132\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\mental_health.lines.psych\n",
      "Saved neutral arousal sentences for mental_health to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\mental_health_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for mental_health: 5424\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\mental_illness.lines.psych\n",
      "Saved neutral arousal sentences for mental_illness to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\mental_illness_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for mental_illness: 680\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\0.0_corpus_preprocessing\\output\\natural_lines_targets\\trauma.lines.psych\n",
      "Saved neutral arousal sentences for trauma to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\sentiment-breadth-intensity\\3_intensity\\synthetic\\input\\baselines\\trauma_neutral_baselines_intensity.csv.\n",
      "Total neutral sentences for trauma: 2588\n",
      "All processing complete.\n"
     ]
    }
   ],
   "source": [
    "%run step0_get_neutral_baselines_intensity.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup examples to inject in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code sets up examples of baseline sentences and their intensity-modified variations (more and less intense) to provide context and guidance for the LLM. \n",
    "# These examples are formatted into a structured prompt to help the model understand how to generate intensity-modified variations for new sentences.\n",
    "\n",
    "@dataclass\n",
    "class Example:\n",
    "    baseline: str\n",
    "    more_intense: str\n",
    "    less_intense: str\n",
    "\n",
    "    def format_for_prompt(self):\n",
    "        return f\"\"\"<baseline>\n",
    "{self.baseline}\n",
    "</baseline>\n",
    "<increased {TARGET_WORD}>\n",
    "{self.more_intense}\n",
    "</increased {TARGET_WORD}>\n",
    "<decreased {TARGET_WORD}>\n",
    "{self.less_intense}\n",
    "</decreased {TARGET_WORD}>\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLES = [\n",
    "    Example(\n",
    "        baseline=\"In a 24-yr-old female patient with a 12-yr history of kleptomania, it appeared that the behavior was maintained because it reduced anxiety in relevant situations.\",\n",
    "        more_intense=\"In a 24-yr-old female patient with a 12-yr history of kleptomania, it appeared that the behavior was maintained because it alleviated intense and overwhelming anxiety that pervaded her daily life.\",\n",
    "        less_intense=\"In a 24-yr-old female patient with a 12-yr history of kleptomania, it appeared that the behavior was maintained because it relieved mild, occasional anxiety in certain situations.\",\n",
    "    ),\n",
    "    Example(\n",
    "        baseline=\"Anxiety, insecurity, and lack of skill in establishing appropriate relationships prevented workers from obtaining adequate bases for evaluation and for effectuation of treatment.\",\n",
    "        more_intense=\"Intense anxiety, profound insecurity, and a lack of skill in establishing appropriate relationships prevented workers from obtaining adequate bases for evaluation and for effectuation of treatment.\",\n",
    "        less_intense=\"Mild anxiety, occasional insecurity, and a lack of skill in establishing appropriate relationships prevented workers from obtaining adequate bases for evaluation and for effectuation of treatment.\",\n",
    "    ),\n",
    "    Example(\n",
    "        baseline=\"The relationship between self-reported fear and anxiety was examined in a large sample of normal Australian children and adolescents.\",\n",
    "        more_intense=\"The relationship between deeply rooted fear and severe anxiety was examined in a large sample of Australian children and adolescents, revealing strong emotional undercurrents.\",\n",
    "        less_intense=\"The relationship between mild fear and occasional anxiety was examined in a large sample of Australian children and adolescents.\",\n",
    "    )\n",
    "]\n",
    "\n",
    "PROMPT_INTRO = f\"\"\"In psychology lexicographic research, we define \"intensity\" as the \"extent to which a word refers to more emotionally or referentially intense phenomena\". Here we study the intensity of the word \"{TARGET_WORD}\"\n",
    "You will be given a sentence with the word \"{TARGET_WORD}\" in it. You will then be asked to write two new sentences: one where the word \"{TARGET_WORD}\" is more intense, and one where it is less intense.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code chunk constructs a structured prompt by combining predefined examples with a new target sentence, queries an LLM to generate intensity-modified variations (more and less intense) \n",
    "# of the target sentence, and extracts the results for further analysis.\n",
    "\n",
    "@dataclass\n",
    "class SentenceToModify:\n",
    "    text: str\n",
    "\n",
    "    def get_prompt(self):\n",
    "        prompt = PROMPT_INTRO\n",
    "        for example in EXAMPLES:\n",
    "            prompt += example.format_for_prompt()\n",
    "            prompt += \"\\n\\n\"\n",
    "        \n",
    "        prompt += f\"\"\"<baseline>\n",
    "{self.text}\n",
    "</baseline>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def parse_response(self, response: str):\n",
    "        # get the sentences inside <more {TARGET_WORD}> and <less {TARGET_WORD}>\n",
    "        increased_variation = response.split(f\"<increased {TARGET_WORD}>\")[1].split(f\"</increased {TARGET_WORD}>\")[0].strip()\n",
    "        decreased_variation = response.split(f\"<decreased {TARGET_WORD}>\")[1].split(f\"</decreased {TARGET_WORD}>\")[0].strip()\n",
    "        return increased_variation, decreased_variation\n",
    "\n",
    "    def get_variations(self) -> list[str]:\n",
    "        \"\"\" Returns a list of two strings: one where the TARGET_WORD is more intense, and one where it is less intense \"\"\"\n",
    "        assert TARGET_WORD in self.text, f\"TARGET_WORD {TARGET_WORD} not found in text\"\n",
    "        prompt = self.get_prompt()\n",
    "        res = sm.generate_text(prompt=prompt, llm_provider=PROVIDER, llm_model=MODEL)\n",
    "        return self.parse_response(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The intense anxiety caused by the impending surgery consumed her, leaving her utterly overwhelmed and profoundly vulnerable, disrupting every aspect of her daily life.',\n",
       " 'The mild anxiety caused by the impending surgery left her feeling a bit uneasy and slightly vulnerable, affecting her daily routine to a small degree.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code initializes a SentenceToModify object with a given sentence and uses the get_variations() method to generate two intensity-modified \n",
    "# versions (more intense and less intense) of the target word within that sentence.\n",
    "\n",
    "sentence = SentenceToModify(text=\"The anxiety caused by impending surgery left her feeling overwhelmed and vulnerable, affecting her daily life.\")\n",
    "sentence.get_variations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Naomi Baes and Chat GPT  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get embeddings for sentences containing targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XL-LEXEME: Get embeddings for sentences containing targets - Using XL-LEXEME - WORKING HERE\n",
    "\n",
    "https://huggingface.co/pierluigic/xl-lexeme\n",
    "https://aclanthology.org/2023.acl-short.135.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\models\n",
      "C:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\models\\xl-lexeme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'xl-lexeme'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\naomi\\onedrive\\comp80004_phdresearch\\research\\models\\xl-lexeme\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from WordTransformer==0.0.1) (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (4.40.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (0.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers->WordTransformer==0.0.1) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers->WordTransformer==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers->WordTransformer==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (1.3.0)\n",
      "Building wheels for collected packages: WordTransformer\n",
      "  Building wheel for WordTransformer (setup.py): started\n",
      "  Building wheel for WordTransformer (setup.py): finished with status 'done'\n",
      "  Created wheel for WordTransformer: filename=WordTransformer-0.0.1-py3-none-any.whl size=14283 sha256=55cb72684542746c4020412ec94d97fa7b14e78a09cdd92b2a7edaa91062fbde\n",
      "  Stored in directory: c:\\users\\naomi\\appdata\\local\\pip\\cache\\wheels\\08\\da\\f5\\6dd50c7f95f05ec4ced4262c9c18ce63dfc7242ac75c4545df\n",
      "Successfully built WordTransformer\n",
      "Installing collected packages: WordTransformer\n",
      "  Attempting uninstall: WordTransformer\n",
      "    Found existing installation: WordTransformer 0.0.1\n",
      "    Uninstalling WordTransformer-0.0.1:\n",
      "      Successfully uninstalled WordTransformer-0.0.1\n",
      "Successfully installed WordTransformer-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Change to the desired directory\n",
    "%cd C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/models\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/pierluigic/xl-lexeme.git\n",
    "\n",
    "# Navigate into the xl-lexeme folder\n",
    "%cd C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/models/xl-lexeme\n",
    "\n",
    "# Install the model using pip\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WORKING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'xl-lexeme'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\naomi\\onedrive\\comp80004_phdresearch\\research\\models\\xl-lexeme\\xl-lexeme\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from WordTransformer==0.0.1) (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (4.40.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (0.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sentence-transformers->WordTransformer==0.0.1) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers->WordTransformer==0.0.1) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->WordTransformer==0.0.1) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers->WordTransformer==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers->WordTransformer==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers->WordTransformer==0.0.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\naomi\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers->WordTransformer==0.0.1) (1.3.0)\n",
      "Building wheels for collected packages: WordTransformer\n",
      "  Building wheel for WordTransformer (setup.py): started\n",
      "  Building wheel for WordTransformer (setup.py): finished with status 'done'\n",
      "  Created wheel for WordTransformer: filename=WordTransformer-0.0.1-py3-none-any.whl size=14283 sha256=725077f0fe61a79a37220c0dbfcc8bfdfa4ab3c75c6790688a1472f0bbd97208\n",
      "  Stored in directory: c:\\users\\naomi\\appdata\\local\\pip\\cache\\wheels\\ab\\45\\c9\\f374bfdd34ef751778ce873c476cd07de9b3ff8a35a1eff56a\n",
      "Successfully built WordTransformer\n",
      "Installing collected packages: WordTransformer\n",
      "  Attempting uninstall: WordTransformer\n",
      "    Found existing installation: WordTransformer 0.0.1\n",
      "    Uninstalling WordTransformer-0.0.1:\n",
      "      Successfully uninstalled WordTransformer-0.0.1\n",
      "Successfully installed WordTransformer-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/pierluigic/xl-lexeme.git\n",
    "\n",
    "# Change to the repository directory and install the package\n",
    "!pip install ./xl-lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27165adb4fd043a096f24e2c26187fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\naomi/.cache\\torch\\sentence_transformers\\pierluigic_xl-lexeme. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: 'C:\\Users\\naomi/.cache\\torch\\sentence_transformers\\pierluigic_xl-lexeme'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    399\u001b[0m         path_or_repo_id,\n\u001b[0;32m    400\u001b[0m         filename,\n\u001b[0;32m    401\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    402\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    403\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    404\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    405\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    406\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    407\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    408\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    409\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    410\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    411\u001b[0m     )\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'C:\\Users\\naomi/.cache\\torch\\sentence_transformers\\pierluigic_xl-lexeme'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mWordTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordTransformer, InputExample\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model with the correct path\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m WordTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpierluigic/xl-lexeme\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      8\u001b[0m examples \u001b[38;5;241m=\u001b[39m InputExample(texts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe quick fox jumps over the lazy dog\u001b[39m\u001b[38;5;124m\"\u001b[39m, positions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m13\u001b[39m])\n",
      "File \u001b[1;32m~\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\models\\xl-lexeme\\WordTransformer\\WordTransformer.py:88\u001b[0m, in \u001b[0;36mWordTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder)\u001b[0m\n\u001b[0;32m     86\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(model_path)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[0;32m     91\u001b[0m     modules \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "File \u001b[1;32m~\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\models\\xl-lexeme\\WordTransformer\\WordTransformer.py:862\u001b[0m, in \u001b[0;36mWordTransformer._load_auto_model\u001b[1;34m(self, model_name_or_path)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03mCreates a simple Transformer + Mean Pooling model and returns the modules\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    861\u001b[0m logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sentence-transformers model found with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Creating a new one with MEAN pooling.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name_or_path))\n\u001b[1;32m--> 862\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m Transformer(model_name_or_path)\n\u001b[0;32m    863\u001b[0m pooling_model \u001b[38;5;241m=\u001b[39m Pooling(transformer_model\u001b[38;5;241m.\u001b[39mget_word_embedding_dimension(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [transformer_model, pooling_model]\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:35\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_seq_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_lower_case\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[1;32m---> 35\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     39\u001b[0m     tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path,\n\u001b[0;32m     40\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    926\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    687\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    688\u001b[0m         configuration_file,\n\u001b[0;32m    689\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    690\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    691\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    692\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    693\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    694\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    695\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    696\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    697\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    698\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    699\u001b[0m     )\n\u001b[0;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:462\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    464\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: 'C:\\Users\\naomi/.cache\\torch\\sentence_transformers\\pierluigic_xl-lexeme'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "# Verify the installation and load the model\n",
    "from WordTransformer import WordTransformer, InputExample\n",
    "\n",
    "# Load the model with the correct path\n",
    "model = WordTransformer('pierluigic/xl-lexeme')\n",
    "\n",
    "# Example usage\n",
    "examples = InputExample(texts=\"the quick fox jumps over the lazy dog\", positions=[10, 13])\n",
    "fox_embedding = model.encode(examples)\n",
    "\n",
    "# Print the embedding to check success\n",
    "print(fox_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Key Operations:\n",
    "1. Target Word Identification: For each sentence in the input files, the script identifies the position of the target word (derived from the file name).\n",
    "2. Embedding Generation: The embeddings are generated for the target word in its context using WordTransformer.\n",
    "3. Dissimilarity Calculation: The script calculates pairwise dissimilarity scores based on cosine similarity between embeddings.\n",
    "4. Output: The script saves these dissimilarity scores into output files in the same directory structure with a _cds_lexeme suffix.\n",
    "\n",
    "Use Cases:\n",
    "1. This script can be used for analyzing semantic change or similarity in context for specific target words across different documents or time periods.\n",
    "2. It could also be useful in clustering, semantic search, or other tasks requiring embeddings of words in specific contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step3_process_sentences_lexeme.py # get cosine dissimilarity scores between sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Combine cds for diff corpora\n",
    "\n",
    "Within each file: The script reads the cosine similarity scores, computes the mean, standard deviation (SD), and standard error (SE) for each file.\n",
    "Aggregating across files: The script then aggregates these statistics (mean, SD, SE) across the random samples (.1 through .10) within each combination of epoch, target term, and injection ratio (_20, _40, _60, _80, _100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process sentences to get cosine dissimilarity scores for each sentence combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step3_process_sentences_5-year.cosine_lexeme.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step3_process_sentences_all-year.cosine_lexeme.py # extend the script above to the all-year samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregate cds scores across relevant groups to get final index (NB TO DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the final combined DataFrame to: output/final_combined.all-year.cds_mpnet.bootstrap.csv\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "%run step4.1_combined.5-year.cosine.mpnet.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step4.1_combined.all-year.cosine.mpnet.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

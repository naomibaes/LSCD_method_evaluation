{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Naomi Baes\n",
    "Aim: Compute change scores (100-0) for bootstrap sampling; ROC (100-0) for stratified random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap sampling (all-year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All differences calculated and saved to final_change_scores_all-year.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load CSV data, drop empty rows, and flatten multi-index columns.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Drop any completely empty rows\n",
    "        df = df.dropna(how='all')\n",
    "\n",
    "        # Flatten multi-index columns if needed\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
    "        \n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "\n",
    "def calculate_diff(df, value_columns, dimension, measure_tag=\"\", measure_type=\"\"):\n",
    "    \"\"\"\n",
    "    Calculates the difference between injection_ratio 100 and 0 for the specified value columns,\n",
    "    and assigns increase or decrease based on specific logic per dataset.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"Dataframe is empty, skipping processing.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if 'inj_ratio' in df.columns:\n",
    "        df = df.rename(columns={'inj_ratio': 'injection_ratio'})\n",
    "    \n",
    "    if 'injection_ratio' not in df.columns:\n",
    "        print(\"Missing 'injection_ratio' column, skipping processing.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_filtered = df[df['injection_ratio'].isin([0, 100])]\n",
    "    if df_filtered.empty:\n",
    "        print(\"No relevant injection ratios found, skipping processing.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    index_col = 'term' if 'term' in df.columns else 'target'\n",
    "    df_pivoted = df_filtered.pivot(index=index_col, columns='injection_ratio', values=value_columns)\n",
    "    df_pivoted.reset_index(inplace=True)  # Ensure index columns are back to normal columns\n",
    "\n",
    "    results = []\n",
    "    for col in value_columns:\n",
    "        diff_col_name = f'{col}_diff{measure_tag}'\n",
    "        df_pivoted[diff_col_name] = df_pivoted[(col, 100)] - df_pivoted[(col, 0)]\n",
    "        temp_df = df_pivoted.loc[:, [index_col, diff_col_name]]\n",
    "        temp_df.rename(columns={index_col: 'target', diff_col_name: 'change_score'}, inplace=True)\n",
    "        \n",
    "        # Apply increase or decrease logic based on column and measure\n",
    "        temp_df['condition'] = np.where(temp_df['change_score'] > 0, \"Increase\", \"Decrease\")\n",
    "        temp_df['dimension'] = dimension\n",
    "        temp_df['measure'] = measure_type\n",
    "        \n",
    "        results.append(temp_df)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "\n",
    "# **Load datasets**\n",
    "df_valence = load_data(\"../1_sentiment/output/baseline_averaged_valence_index_all-year_normalized.csv\")\n",
    "df_arousal = load_data(\"../3_intensity/output/baseline_averaged_arousal_index_all-year_normalized.csv\")\n",
    "df_cosine = load_data(\"../2_breadth/output/baseline_final_combined.all-year.cds_mpnet.csv\")\n",
    "df_valence_absa = load_data(\"../1_sentiment/output/absa_averaged_sentiment_index_all-year_with_se.csv\")\n",
    "df_cosine_lexeme = load_data(\"../2_breadth/output/baseline_final_combined.all-year.cds_lexeme.csv\")\n",
    "df_xl_lexeme = load_data(\"../xl_lexeme_results.csv\")  # New dataset\n",
    "\n",
    "# **Calculate differences for original datasets**\n",
    "valence_diff = calculate_diff(df_valence, ['avg_valence_index_negative', 'avg_valence_index_positive'], \"Sentiment\", \"\", \"SIB\")\n",
    "arousal_diff = calculate_diff(df_arousal, ['avg_arousal_index_high', 'avg_arousal_index_low'], \"Intensity\", \"\", \"SIB\")\n",
    "cosine_diff = calculate_diff(df_cosine, ['cosine_dissim_mean'], \"Breadth\", \"\", \"SIB\")\n",
    "valence_absa_diff = calculate_diff(df_valence_absa, ['avg_valence_index_negative', 'avg_valence_index_positive'], \"Sentiment\", \"_absa\", \"absa\")\n",
    "cosine_lexeme_diff = calculate_diff(df_cosine_lexeme, ['cosine_dissim_mean'], \"Breadth\", \"_lexeme\", \"Breadth (lexeme)\")\n",
    "\n",
    "# **Process xl_lexeme_results.csv to extract 100_0 column**\n",
    "if df_xl_lexeme is not None:\n",
    "    df_xl_lexeme = df_xl_lexeme[['target', 'dimension', 'condition', '100_0']].copy()\n",
    "    df_xl_lexeme.rename(columns={'100_0': 'change_score'}, inplace=True)\n",
    "\n",
    "    # **Fix inconsistent casing for 'dimension' values**\n",
    "    df_xl_lexeme['dimension'] = df_xl_lexeme['dimension'].str.capitalize()\n",
    "\n",
    "    # **Ensure 'condition' is correctly mapped**\n",
    "    df_xl_lexeme['condition'] = df_xl_lexeme['condition'].replace({\n",
    "        'positive': 'Increase',\n",
    "        'negative': 'Decrease',\n",
    "        'high': 'Increase',\n",
    "        'low': 'Decrease',\n",
    "        'neutral': 'Neutral'\n",
    "    })\n",
    "\n",
    "    # **Ensure 'condition' is filled correctly for Breadth and Intensity**\n",
    "    df_xl_lexeme.loc[df_xl_lexeme['dimension'].isin(['Breadth', 'Intensity']), 'condition'] = df_xl_lexeme['condition']\n",
    "\n",
    "    # **Add measure label**\n",
    "    df_xl_lexeme['measure'] = 'LSC'\n",
    "\n",
    "    # **Ensure proper column ordering**\n",
    "    df_xl_lexeme = df_xl_lexeme[['target', 'change_score', 'condition', 'dimension', 'measure']]\n",
    "\n",
    "# **Combine all results into a single DataFrame**\n",
    "final_results = pd.concat(\n",
    "    [valence_diff, arousal_diff, cosine_diff, valence_absa_diff, cosine_lexeme_diff, df_xl_lexeme], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# **Drop duplicate columns & ensure uniform headers**\n",
    "final_results = final_results.loc[:, ~final_results.columns.duplicated()].copy()\n",
    "\n",
    "# **Save the final DataFrame to a CSV file**\n",
    "final_results.to_csv(\"final_change_scores_all-year.csv\", index=False)\n",
    "print(\"All differences calculated and saved to final_change_scores_all-year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix misalignment and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Misaligned rows fixed, target names corrected, and negative values added to 'decrease' condition. Saved to 'final_change_scores_all-year.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the misaligned dataset\n",
    "df = pd.read_csv(\"final_change_scores_all-year.csv\", dtype=str)\n",
    "\n",
    "# Ensure proper column names\n",
    "expected_columns = [\"target\", \"change_score\", \"condition\", \"dimension\", \"measure\"]\n",
    "\n",
    "# Identify rows that are misaligned (leading NaNs)\n",
    "misaligned_rows = df[df.isna().sum(axis=1) > 2].index\n",
    "\n",
    "# Shift the LSC rows left by counting the number of empty columns\n",
    "for idx in misaligned_rows:\n",
    "    row_values = df.loc[idx].dropna().tolist()  # Remove NaNs and convert to list\n",
    "    if len(row_values) == len(expected_columns):  # Ensure full alignment\n",
    "        df.loc[idx, expected_columns] = row_values\n",
    "\n",
    "# Drop remaining NaN-filled columns\n",
    "df = df[expected_columns]\n",
    "\n",
    "# **Fix 'health' and 'illness' in the 'target' column**\n",
    "df[\"target\"] = df[\"target\"].replace({\n",
    "    \"health\": \"mental_health\",\n",
    "    \"illness\": \"mental_illness\"\n",
    "})\n",
    "\n",
    "# **Ensure 'change_score' is numeric**\n",
    "df[\"change_score\"] = pd.to_numeric(df[\"change_score\"], errors=\"coerce\")\n",
    "\n",
    "# **Add a negative value to the 'decrease' condition for all change scores**\n",
    "df.loc[(df[\"condition\"].str.lower() == \"decrease\") & (df[\"measure\"].str.lower() == \"lsc\"), \"change_score\"] *= -1\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "df.to_csv(\"final_change_scores_all-year.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Misaligned rows fixed, target names corrected, and negative values added to 'decrease' condition. Saved to 'final_change_scores_all-year.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Random Sampling (5-year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rate of change score for SIB measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Load datasets**\n",
    "df_valence = load_data(\"../1_sentiment/output/baseline_averaged_valence_index_all-year_normalized.csv\")\n",
    "df_arousal = load_data(\"../3_intensity/output/baseline_averaged_arousal_index_all-year_normalized.csv\")\n",
    "df_cosine = load_data(\"../2_breadth/output/baseline_final_combined.all-year.cds_mpnet.csv\")\n",
    "df_valence_absa = load_data(\"../1_sentiment/output/absa_averaged_sentiment_index_all-year_with_se.csv\")\n",
    "df_cosine_lexeme = load_data(\"../2_breadth/output/baseline_final_combined.all-year.cds_lexeme.csv\")\n",
    "df_xl_lexeme = load_data(\"../xl_lexeme_results.csv\")  # New dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valence = load_data(\"../1_sentiment/output/baseline_averaged_valence_index_5-year_normalized.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to: final_change_scores_5-year_SIB.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "file_path_valence = \"../1_sentiment/output/baseline_averaged_valence_index_5-year_normalized.csv\"\n",
    "file_path_arousal = \"../3_intensity/output/baseline_averaged_arousal_index_5-year_normalized.csv\"\n",
    "file_path_breadth = \"../2_breadth/output/baseline_final_combined.5-year.cds_mpnet.csv\"\n",
    "\n",
    "df_valence = pd.read_csv(file_path_valence)\n",
    "df_arousal = pd.read_csv(file_path_arousal)\n",
    "df_breadth = pd.read_csv(file_path_breadth)\n",
    "\n",
    "# Convert epoch to numeric start year for sorting\n",
    "for df in [df_valence, df_arousal, df_breadth]:\n",
    "    df['epoch_start'] = df['epoch'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Rename columns in breadth dataset for consistency\n",
    "df_breadth.rename(columns={'term': 'target', 'inj_ratio': 'injection_ratio'}, inplace=True)\n",
    "\n",
    "# Function to compute total change and average rate of change per epoch\n",
    "def compute_change_metrics(df, metric_high, metric_low, measure, dimension, condition_high, condition_low):\n",
    "    # Keep only 0% and 100% injection ratios\n",
    "    df = df[df['injection_ratio'].isin([0, 100])]\n",
    "\n",
    "    # Pivot table to get values for 0% and 100% injections\n",
    "    if metric_high != metric_low:  # Sentiment & Intensity: Two different metrics\n",
    "        df_pivot = df.pivot(index=['target', 'epoch_start'], columns='injection_ratio', values=[metric_high, metric_low])\n",
    "    else:  # Breadth: Single metric\n",
    "        df_pivot = df.pivot(index=['target', 'epoch_start'], columns='injection_ratio', values=[metric_high])\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    df_pivot.columns = ['_'.join(map(str, col)) for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    required_cols = [f'{metric_high}_0', f'{metric_high}_100']\n",
    "    if metric_high != metric_low:  # Sentiment & Intensity\n",
    "        required_cols += [f'{metric_low}_0', f'{metric_low}_100']\n",
    "    df_pivot = df_pivot.dropna(subset=required_cols)\n",
    "\n",
    "    # Compute change scores\n",
    "    df_pivot[f'change_score_high'] = df_pivot[f'{metric_high}_100'] - df_pivot[f'{metric_high}_0']\n",
    "    \n",
    "    if metric_high != metric_low:  # Sentiment & Intensity\n",
    "        df_pivot[f'change_score_low'] = df_pivot[f'{metric_low}_100'] - df_pivot[f'{metric_low}_0']\n",
    "\n",
    "    # Compute total change for both conditions\n",
    "    df_total_change = df_pivot.groupby('target')[['change_score_high']].sum().reset_index()\n",
    "    df_total_change.rename(columns={'change_score_high': 'total_change'}, inplace=True)\n",
    "\n",
    "    # Compute number of epochs per target\n",
    "    n_epochs = df_pivot.groupby('target')['epoch_start'].nunique().reset_index()\n",
    "    n_epochs.rename(columns={'epoch_start': 'n_epochs'}, inplace=True)\n",
    "\n",
    "    # Merge total change and number of epochs\n",
    "    df_final = df_total_change.merge(n_epochs, on='target')\n",
    "\n",
    "    # Compute average rate of change per epoch\n",
    "    df_final['avg_rate_of_change'] = df_final['total_change'] / df_final['n_epochs']\n",
    "\n",
    "    # Add measure, dimension, and condition columns\n",
    "    df_final['measure'] = measure\n",
    "    df_final['dimension'] = dimension\n",
    "    df_final['condition'] = condition_high  # Default to high/increase\n",
    "\n",
    "    # Separate high and low condition rows only for Sentiment & Intensity\n",
    "    if metric_high != metric_low:\n",
    "        df_total_change_low = df_pivot.groupby('target')[['change_score_low']].sum().reset_index()\n",
    "        df_total_change_low.rename(columns={'change_score_low': 'total_change'}, inplace=True)\n",
    "\n",
    "        df_final_low = df_total_change_low.merge(n_epochs, on='target')\n",
    "        df_final_low['avg_rate_of_change'] = df_final_low['total_change'] / df_final_low['n_epochs']\n",
    "        df_final_low['measure'] = measure\n",
    "        df_final_low['dimension'] = dimension\n",
    "        df_final_low['condition'] = condition_low  # Low condition for Sentiment & Intensity\n",
    "\n",
    "        # Combine high and low conditions\n",
    "        df_final = pd.concat([df_final, df_final_low], ignore_index=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Compute change metrics for valence (Sentiment), arousal (Intensity), and breadth (Breadth)\n",
    "df_valence_final = compute_change_metrics(df_valence, 'avg_valence_index_positive', 'avg_valence_index_negative', 'SIB', 'Sentiment', 'positive', 'negative')\n",
    "df_arousal_final = compute_change_metrics(df_arousal, 'avg_arousal_index_high', 'avg_arousal_index_low', 'SIB', 'Intensity', 'high', 'low')\n",
    "df_breadth_final = compute_change_metrics(df_breadth, 'cosine_dissim_mean', 'cosine_dissim_mean', 'SIB', 'Breadth', 'increase', 'increase')\n",
    "\n",
    "# Merge final outputs\n",
    "df_final_output = pd.concat([df_valence_final, df_arousal_final, df_breadth_final], ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "output_file_path = \"final_change_scores_5-year_SIB.csv\"\n",
    "df_final_output.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the output file location\n",
    "print(f\"Final output saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to: final_change_scores_5-year_ABSA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path_absa = \"../1_sentiment/output/absa_averaged_sentiment_index_5-year.csv\"  # Change this to the actual file path\n",
    "df_absa = pd.read_csv(file_path_absa)\n",
    "\n",
    "# Convert epoch to numeric start year for sorting\n",
    "df_absa['epoch_start'] = df_absa['epoch'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Function to compute total change and average rate of change per epoch\n",
    "def compute_change_metrics(df, metric_high, metric_low, measure, dimension, condition_high, condition_low):\n",
    "    # Keep only 0% and 100% injection ratios\n",
    "    df = df[df['injection_ratio'].isin([0, 100])]\n",
    "\n",
    "    # Pivot table to get values for 0% and 100% injections\n",
    "    df_pivot = df.pivot(index=['target', 'epoch_start'], columns='injection_ratio', values=[metric_high, metric_low])\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    df_pivot.columns = ['_'.join(map(str, col)) for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    required_cols = [f'{metric_high}_0', f'{metric_high}_100', f'{metric_low}_0', f'{metric_low}_100']\n",
    "    df_pivot = df_pivot.dropna(subset=required_cols)\n",
    "\n",
    "    # Compute change scores for both conditions\n",
    "    df_pivot[f'change_score_high'] = df_pivot[f'{metric_high}_100'] - df_pivot[f'{metric_high}_0']\n",
    "    df_pivot[f'change_score_low'] = df_pivot[f'{metric_low}_100'] - df_pivot[f'{metric_low}_0']\n",
    "\n",
    "    # Compute total change for both conditions\n",
    "    df_total_change = df_pivot.groupby('target')[['change_score_high']].sum().reset_index()\n",
    "    df_total_change.rename(columns={'change_score_high': 'total_change'}, inplace=True)\n",
    "\n",
    "    # Compute number of epochs per target\n",
    "    n_epochs = df_pivot.groupby('target')['epoch_start'].nunique().reset_index()\n",
    "    n_epochs.rename(columns={'epoch_start': 'n_epochs'}, inplace=True)\n",
    "\n",
    "    # Merge total change and number of epochs\n",
    "    df_final = df_total_change.merge(n_epochs, on='target')\n",
    "\n",
    "    # Compute average rate of change per epoch\n",
    "    df_final['avg_rate_of_change'] = df_final['total_change'] / df_final['n_epochs']\n",
    "\n",
    "    # Add measure, dimension, and condition columns\n",
    "    df_final['measure'] = measure\n",
    "    df_final['dimension'] = dimension\n",
    "    df_final['condition'] = condition_high  # Default to high\n",
    "\n",
    "    # Separate high and low condition rows\n",
    "    df_total_change_low = df_pivot.groupby('target')[['change_score_low']].sum().reset_index()\n",
    "    df_total_change_low.rename(columns={'change_score_low': 'total_change'}, inplace=True)\n",
    "\n",
    "    df_final_low = df_total_change_low.merge(n_epochs, on='target')\n",
    "    df_final_low['avg_rate_of_change'] = df_final_low['total_change'] / df_final_low['n_epochs']\n",
    "    df_final_low['measure'] = measure\n",
    "    df_final_low['dimension'] = dimension\n",
    "    df_final_low['condition'] = condition_low  # Low condition\n",
    "\n",
    "    # Combine high and low conditions\n",
    "    df_final = pd.concat([df_final, df_final_low], ignore_index=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Compute change metrics for ABSA (Sentiment)\n",
    "df_absa_final = compute_change_metrics(df_absa, 'avg_valence_index_positive', 'avg_valence_index_negative', 'ABSA', 'Sentiment', 'positive', 'negative')\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "output_file_path = \"final_change_scores_5-year_ABSA.csv\"\n",
    "df_absa_final.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the output file location\n",
    "print(f\"Final output saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to: final_change_scores_5-year_Lexeme.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path_breadth = \"../2_breadth/output/baseline_final_combined.5-year.cds_lexeme.csv\"  # Update this to your actual file path\n",
    "df_breadth = pd.read_csv(file_path_breadth)\n",
    "\n",
    "# Convert epoch to numeric start year for sorting\n",
    "df_breadth['epoch_start'] = df_breadth['epoch'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Rename columns for consistency\n",
    "df_breadth.rename(columns={'term': 'target', 'inj_ratio': 'injection_ratio'}, inplace=True)\n",
    "\n",
    "# Function to compute total change and average rate of change per epoch\n",
    "def compute_change_metrics(df, metric, measure, dimension, condition):\n",
    "    # Keep only 0% and 100% injection ratios\n",
    "    df = df[df['injection_ratio'].isin([0, 100])]\n",
    "\n",
    "    # Pivot table to get values for 0% and 100% injections\n",
    "    df_pivot = df.pivot(index=['target', 'epoch_start'], columns='injection_ratio', values=metric)\n",
    "\n",
    "    # Flatten MultiIndex columns (Fix applied)\n",
    "    df_pivot.columns = [str(col) for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    required_cols = ['0', '100']\n",
    "    df_pivot = df_pivot.dropna(subset=required_cols)\n",
    "\n",
    "    # Compute change scores\n",
    "    df_pivot['change_score'] = df_pivot['100'] - df_pivot['0']\n",
    "\n",
    "    # Compute total change\n",
    "    df_total_change = df_pivot.groupby('target')[['change_score']].sum().reset_index()\n",
    "    df_total_change.rename(columns={'change_score': 'total_change'}, inplace=True)\n",
    "\n",
    "    # Compute number of epochs per target\n",
    "    n_epochs = df_pivot.groupby('target')['epoch_start'].nunique().reset_index()\n",
    "    n_epochs.rename(columns={'epoch_start': 'n_epochs'}, inplace=True)\n",
    "\n",
    "    # Merge total change and number of epochs\n",
    "    df_final = df_total_change.merge(n_epochs, on='target')\n",
    "\n",
    "    # Compute average rate of change per epoch\n",
    "    df_final['avg_rate_of_change'] = df_final['total_change'] / df_final['n_epochs']\n",
    "\n",
    "    # Add measure, dimension, and condition columns\n",
    "    df_final['measure'] = measure\n",
    "    df_final['dimension'] = dimension\n",
    "    df_final['condition'] = condition\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Compute change metrics for Breadth using Lexeme as the measure\n",
    "df_breadth_final = compute_change_metrics(df_breadth, 'cosine_dissim_mean', 'Lexeme', 'Breadth', 'increase')\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "output_file_path = \"final_change_scores_5-year_Lexeme.csv\"\n",
    "df_breadth_final.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the output file location\n",
    "print(f\"Final output saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to: final_change_scores_5-year_LSC.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file_paths = [\n",
    "    \"../xl-lexeme_dissimilarity_5-year_breadth.csv\",\n",
    "    \"../xl-lexeme_dissimilarity_5-year_negative_sentiment.csv\",\n",
    "    \"../xl-lexeme_dissimilarity_5-year_positive_sentiment.csv\"\n",
    "]\n",
    "\n",
    "# Extract dimension and condition from file names\n",
    "def extract_metadata(file_name):\n",
    "    if \"breadth\" in file_name:\n",
    "        return \"Breadth\", \"increase\"\n",
    "    elif \"negative_sentiment\" in file_name:\n",
    "        return \"Sentiment\", \"negative\"\n",
    "    elif \"positive_sentiment\" in file_name:\n",
    "        return \"Sentiment\", \"positive\"\n",
    "    else:\n",
    "        return None, None  # Fallback case (shouldn't happen if files are named correctly)\n",
    "\n",
    "# Function to process each file\n",
    "def process_file(file_path):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Extract metadata from filename\n",
    "    dimension, condition = extract_metadata(file_path)\n",
    "    \n",
    "    # Convert year to numeric start year for sorting\n",
    "    df['epoch_start'] = df['year'].astype(str).str.split('-').str[0].astype(int)\n",
    "\n",
    "    # Keep only injection_level == 0_100\n",
    "    df = df[df['injection_level'] == \"0_100\"]\n",
    "\n",
    "    # Compute total change\n",
    "    df_total_change = df.groupby('target')[['avg_dissimilarity']].sum().reset_index()\n",
    "    df_total_change.rename(columns={'avg_dissimilarity': 'total_change'}, inplace=True)\n",
    "\n",
    "    # Compute number of epochs per target\n",
    "    n_epochs = df.groupby('target')['epoch_start'].nunique().reset_index()\n",
    "    n_epochs.rename(columns={'epoch_start': 'n_epochs'}, inplace=True)\n",
    "\n",
    "    # Merge total change and number of epochs\n",
    "    df_final = df_total_change.merge(n_epochs, on='target')\n",
    "\n",
    "    # Compute average rate of change per epoch\n",
    "    df_final['avg_rate_of_change'] = df_final['total_change'] / df_final['n_epochs']\n",
    "\n",
    "    # Add measure, dimension, and condition columns\n",
    "    df_final['measure'] = \"LSC\"\n",
    "    df_final['dimension'] = dimension\n",
    "    df_final['condition'] = condition\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Process all files and concatenate results\n",
    "df_final_output = pd.concat([process_file(file) for file in file_paths], ignore_index=True)\n",
    "\n",
    "# Save final dataframe to CSV\n",
    "output_file_path = \"final_change_scores_5-year_LSC.csv\"\n",
    "df_final_output.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display output file location\n",
    "print(f\"Final output saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined output saved to: final_combined_change_scores_5-year.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of input files\n",
    "file_paths = [\n",
    "    \"final_change_scores_5-year_ABSA.csv\",\n",
    "    \"final_change_scores_5-year_Lexeme.csv\",\n",
    "    \"final_change_scores_5-year_LSC.csv\",\n",
    "    \"final_change_scores_5-year_SIB.csv\"\n",
    "]\n",
    "\n",
    "# Load all files and concatenate them\n",
    "df_combined = pd.concat([pd.read_csv(file) for file in file_paths], ignore_index=True)\n",
    "\n",
    "# Convert 'target' values: 'health' → 'mental_health', 'illness' → 'mental_illness'\n",
    "df_combined['target'] = df_combined['target'].replace({\n",
    "    'health': 'mental_health',\n",
    "    'illness': 'mental_illness'\n",
    "})\n",
    "\n",
    "# Apply negative sign for LSC measure when condition is 'negative' or 'low'\n",
    "df_combined.loc[\n",
    "    (df_combined['measure'] == 'LSC') & (df_combined['condition'].isin(['negative', 'low'])),\n",
    "    ['total_change', 'avg_rate_of_change']\n",
    "] *= -1  # Multiply by -1 to flip sign\n",
    "\n",
    "# Save final combined dataframe to CSV\n",
    "output_file_path = \"final_combined_change_scores_5-year.csv\"\n",
    "df_combined.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display output file location\n",
    "print(f\"Final combined output saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Sentiment variations using LLMs\n",
    "\n",
    "Author: Raphael Merx\n",
    "Input: a baseline sentence; Output: variations of this sentence where a target word has more positive or negative sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplemind python-dotenv pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import simplemind as sm\n",
    "from typing import Literal, List\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "TARGET_WORD_CHOICES = Literal['abuse', 'anxiety', 'depression', 'mental_health', 'mental_illness', 'trauma']\n",
    "\n",
    "TARGET_WORD: TARGET_WORD_CHOICES = 'mental_illness'\n",
    "#TARGET_WORD_HUMAN = TARGET_WORD.replace('_', ' ') #Note:This is not needed unless there is a good reason as it makes it easier for processing down the line. \n",
    "\n",
    "MAX_BASELINES = 10\n",
    "\n",
    "# can be changed to gemini, see https://pypi.org/project/simplemind/\n",
    "PROVIDER = \"openai\"\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get neutral baseline sentences from corpus for LLM input for each target\n",
    "\n",
    "- **Script 1 Aim**: This script computes sentence-level sentiment scores using the NRC-VAD lexicon for a corpus of target terms spanning 1970–2019. It dynamically determines neutral sentiment ranges for each 5-year epoch by expanding outward from the median sentiment score within the interquartile range (Q1–Q3) until at least 500 sentences are included, capped at 1500. The selected sentences are saved to CSV files for each target and epoch, and a summary file logs the dynamic ranges and counts.\n",
    "\n",
    "- **Script 2 Aim**: This script processes pre-saved baseline CSV files to calculate sentence counts by year and 5-year epochs for multiple target terms. It generates \"year_count_lines.csv\" and \"epoch_count_lines.csv\" summarizing these counts and creates an epoch-based bar plot visualizing sentence distributions across the specified epochs for each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\abuse_2015-2019.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\anxiety_2015-2019.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\depression_2015-2019.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_health_2015-2019.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\mental_illness_2015-2019.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1970-1974.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1975-1979.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1980-1984.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1985-1989.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1990-1994.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_1995-1999.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_2000-2004.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_2005-2009.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_2010-2014.baseline_1500_sentences.csv\n",
      "Processing file: c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\trauma_2015-2019.baseline_1500_sentences.csv\n",
      "Year count summary saved to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\output\\year_count_lines.csv.\n",
      "Epoch count summary saved to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\output\\epoch_count_lines.csv.\n",
      "Epoch plot saved to c:\\Users\\naomi\\OneDrive\\COMP80004_PhDResearch\\RESEARCH\\PROJECTS\\3_evaluation+validation - ACL 2025\\ICL\\1_sentiment\\synthetic\\input\\baselines\\output\\epoch_counts.png.\n"
     ]
    }
   ],
   "source": [
    "#%run step0_get_neutral_baselines_sentiment.py\n",
    "#%run step1_plot_neutral_baselines_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup examples to inject in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    baseline: str\n",
    "    positive_sentiment: str\n",
    "    negative_sentiment: str\n",
    "\n",
    "    def format_for_prompt(self):\n",
    "        return f\"\"\"<baseline>\n",
    "{self.baseline}\n",
    "</baseline>\n",
    "<positive {TARGET_WORD_HUMAN}>\n",
    "{self.positive_sentiment}\n",
    "</positive {TARGET_WORD_HUMAN}>\n",
    "<negative {TARGET_WORD_HUMAN}>\n",
    "{self.negative_sentiment}\n",
    "</negative {TARGET_WORD_HUMAN}>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_example_data(word: TARGET_WORD_CHOICES) -> pd.DataFrame:\n",
    "        # find the sentiment_example_sentences.xlsx file in the `input` folder\n",
    "        filepath = os.path.join('input', f'sentiment_example_sentences.xlsx')\n",
    "        # read to a dataframe\n",
    "        df = pd.read_excel(filepath)\n",
    "        # filter rows where `target` column is equal to the `word` argument\n",
    "        df = df[df['target'] == word]\n",
    "        print(f\"Loaded {len(df)} examples for the term '{word}'\")\n",
    "        return df\n",
    "\n",
    "example_data = Example.read_example_data(TARGET_WORD)\n",
    "\n",
    "EXAMPLES = [\n",
    "    Example(\n",
    "        baseline=row['baseline'],\n",
    "        positive_sentiment=row['positive_sentiment'],\n",
    "        negative_sentiment=row['negative_sentiment']\n",
    "    )\n",
    "    for _, row in example_data.iterrows()\n",
    "]\n",
    "\n",
    "PROMPT_INTRO = f\"\"\"\n",
    "In psychology research, 'Sentiment' is defined as “a term’s acquisition of a more positive or negative connotation.” \n",
    "Here we study the sentiment of the term '{TARGET_WORD_HUMAN}'.\n",
    "\n",
    "You will be given a sentence with the term '{TARGET_WORD_HUMAN}' in it. Your task is to write two new sentences:\n",
    "- One where the term '{TARGET_WORD_HUMAN}' carries a more positive connotation.\n",
    "- One where the term '{TARGET_WORD_HUMAN}' carries a more negative connotation.\n",
    "\n",
    "Important Guidelines:\n",
    "- Retain the original structure and context of the baseline sentence as much as possible.\n",
    "- Make only small, targeted adjustments to alter the sentiment of the term '{TARGET_WORD_HUMAN}'.\n",
    "- Do not add or remove key concepts or introduce entirely new elements not implied in the baseline.\n",
    "- Do not replace the target term with another word.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: old prompt\n",
    "PROMPT_INTRO = f\"\"\"In psychology lexicographic research, we define \"sentiment\" as the \"a term’s acquisition of a more positive or negative connotation\". Here we study the sentiment of the term \"{TARGET_WORD_HUMAN}\"\n",
    "You will be given a sentence with the term \"{TARGET_WORD_HUMAN}\" in it. You will then be asked to write two new sentences: one where the term \"{TARGET_WORD_HUMAN}\" carries a more positive connotation, and one where it carries a more negative connotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a total of 403 baseline sentences, sampling 10\n",
      "In psychology lexicographic research, we define \"sentiment\" as the \"a term’s acquisition of a more positive or negative connotation\". Here we study the sentiment of the term \"mental illness\"\n",
      "You will be given a sentence with the term \"mental illness\" in it. You will then be asked to write two new sentences: one where the term \"mental illness\" carries a more positive connotation, and one where it carries a more negative connotation.\n",
      "\n",
      "<baseline>\n",
      "The research explored the stigma surrounding mental illness in different cultures.\n",
      "</baseline>\n",
      "<positive mental illness>\n",
      "The research highlighted campaigns that reduced stigma and improved perceptions of mental illness.\n",
      "</positive mental illness>\n",
      "<negative mental illness>\n",
      "The research revealed that stigma surrounding mental illness often led to delayed treatment and isolation.\n",
      "</negative mental illness>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "The study analyzed access to care for individuals with mental illness.\n",
      "</baseline>\n",
      "<positive mental illness>\n",
      "The study highlighted initiatives that increased access to care and improved outcomes for individuals with mental illness.\n",
      "</positive mental illness>\n",
      "<negative mental illness>\n",
      "The study revealed significant barriers to care for individuals with mental illness exacerbating their challenges.\n",
      "</negative mental illness>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "The paper reviewed the portrayal of mental illness in popular media.\n",
      "</baseline>\n",
      "<positive mental illness>\n",
      "The paper celebrated efforts to depict mental illness accurately reducing stereotypes and misinformation.\n",
      "</positive mental illness>\n",
      "<negative mental illness>\n",
      "The paper criticized negative portrayals of mental illness in media that perpetuated harmful stereotypes.\n",
      "</negative mental illness>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "The study examined the intersection of poverty and mental illness.\n",
      "</baseline>\n",
      "<positive mental illness>\n",
      "The study highlighted programs that addressed poverty and improved mental illness outcomes.\n",
      "</positive mental illness>\n",
      "<negative mental illness>\n",
      "The study found that poverty exacerbated the prevalence and severity of mental illness.\n",
      "</negative mental illness>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "The research investigated family dynamics and mental illness.\n",
      "</baseline>\n",
      "<positive mental illness>\n",
      "The research highlighted supportive family environments that improved mental illness recovery.\n",
      "</positive mental illness>\n",
      "<negative mental illness>\n",
      "The research revealed that unsupportive family dynamics worsened mental illness symptoms and outcomes.\n",
      "</negative mental illness>\n",
      "\n",
      "\n",
      "<baseline>\n",
      "In this setting, the treatment gap between human resources for and the burden of disease for mental illness is as high as 85.\n",
      "</baseline>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SentenceToModify:\n",
    "    text: str\n",
    "    positive_variation: str = None\n",
    "    negative_variation: str = None\n",
    "\n",
    "    def get_prompt(self):\n",
    "        prompt = PROMPT_INTRO\n",
    "        for example in EXAMPLES:\n",
    "            prompt += example.format_for_prompt()\n",
    "            prompt += \"\\n\\n\"\n",
    "        \n",
    "        prompt += f\"\"\"<baseline>\n",
    "{self.text}\n",
    "</baseline>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def parse_response(self, response: str):\n",
    "        # get the sentences inside <positive {TARGET_WORD}> and <negative {TARGET_WORD}>\n",
    "        self.positive_variation = response.split(f\"<positive {TARGET_WORD_HUMAN}>\")[1].split(f\"</positive {TARGET_WORD_HUMAN}>\")[0].strip()\n",
    "        self.negative_variation = response.split(f\"<negative {TARGET_WORD_HUMAN}>\")[1].split(f\"</negative {TARGET_WORD_HUMAN}>\")[0].strip()\n",
    "        return self.positive_variation, self.negative_variation\n",
    "\n",
    "    def get_variations(self) -> list[str]:\n",
    "        \"\"\" Returns a list of two strings: one where the TARGET_WORD has a more positive connotation, and one where it has a more negative one. \"\"\"\n",
    "        assert TARGET_WORD_HUMAN in self.text, f\"TARGET_WORD {TARGET_WORD_HUMAN} not found in {self.text}\"\n",
    "        prompt = self.get_prompt()\n",
    "        res = sm.generate_text(prompt=prompt, llm_provider=PROVIDER, llm_model=MODEL)\n",
    "        return self.parse_response(res)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_baselines(word: TARGET_WORD_CHOICES) -> List[str]:\n",
    "        # find the baselines.csv file in the `input` folder\n",
    "        filepath = os.path.join('input', 'baselines', f'{word}_neutral_baselines_sentiment.csv')\n",
    "        df = pd.read_csv(filepath)\n",
    "        # return the `sentence` column as a list\n",
    "        print(f\"Loaded a total of {len(df)} baseline sentences, sampling {MAX_BASELINES}\")\n",
    "        baselines = df['sentence'].tolist()\n",
    "        baselines = random.sample(baselines, MAX_BASELINES) if len(baselines) > MAX_BASELINES else baselines\n",
    "        baselines = [s.replace(TARGET_WORD, TARGET_WORD_HUMAN) for s in baselines]\n",
    "        return baselines\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_sentences(sentences: List['SentenceToModify']):\n",
    "        output_file = os.path.join('output', f'{TARGET_WORD}_synthetic_sentences.csv')\n",
    "        df = pd.DataFrame([{'baseline': s.text, 'positive_variation': s.positive_variation, 'negative_variation': s.negative_variation} for s in sentences])\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {len(sentences)} sentences to {output_file}\")\n",
    "    \n",
    "\n",
    "baselines = SentenceToModify.load_baselines(TARGET_WORD)\n",
    "sentence = SentenceToModify(text=baselines[0])\n",
    "print(sentence.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 sentences to output/mental_illness_synthetic_sentences.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for baseline in tqdm(baselines):\n",
    "    sentence = SentenceToModify(text=baseline)\n",
    "    positive_variation, negative_variation = sentence.get_variations()\n",
    "    sentences.append(sentence)\n",
    "\n",
    "SentenceToModify.save_sentences(sentences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
